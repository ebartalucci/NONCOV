{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NONCOVToolbox: Step 5\n",
    "## Neural Network Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for generation of a dataset for Deep Learning predictions.\n",
    "\n",
    "For one-hot encodings, i need to flag each entry of the dataset to be able to cluster the shifts according to the noncovalent interaction type.\n",
    "\n",
    "- known drawbacks:\n",
    "    - not all nuclei (shifts) will actually be involved in the noncov interaction, therefore i expect the predictions to be biased toward shielded values\n",
    " \n",
    "one way to restructure the database is to write a small function that parses through the 'Molecule' column and creates a new column called 'NCI' where it appends the type of nci based on the number encountered in the molecule title. Ettore sei un cazzo di genio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pathlib as Path\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "#NONCOVHeader.print_header()\n",
    "\n",
    "# Pre work on molecular geometries\n",
    "from noncov import StructureModifier\n",
    "\n",
    "# OrcaAnalysis module for postprocessing of DFT calculations\n",
    "from noncov import OrcaAnalysis\n",
    "\n",
    "# Graph molecular representations\n",
    "from noncov import MolecularGraph\n",
    "\n",
    "# Functions to store data in dataframes\n",
    "from noncov import MachineLearning\n",
    "\n",
    "# Show performance and features of various NMR functions in module\n",
    "from noncov import NMRFunctions\n",
    "\n",
    "# Display the molecule while its displaced, not yet interactive in Jupyter but interactive in VS Code\n",
    "from noncov import MolView\n",
    "\n",
    "# Disable printing\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore printing\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory is: /Users/ettorebartalucci/Desktop/NONCOV/results\n",
      "Current scratch directory is: /Users/ettorebartalucci/Desktop/NONCOV/scratch\n",
      "Normalized path using os.path: /Users/ettorebartalucci/Desktop/NONCOV/scratch\n",
      "Dataset directory is: /Users/ettorebartalucci/Desktop/NONCOV/scratch/GenerateMLDataset/data/\n",
      "Normalized path using os.path: /Users/ettorebartalucci/Desktop/NONCOV/scratch/GenerateMLDataset/data/\n"
     ]
    }
   ],
   "source": [
    "# Get work directory and scratch folder for the output data\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current work directory is: {current_dir}')\n",
    "\n",
    "scratch_dir = os.path.abspath(os.path.join('..', 'scratch'))\n",
    "print(f'Current scratch directory is: {scratch_dir}')\n",
    "scratch_dir = OrcaAnalysis().convert_path(scratch_dir)\n",
    "\n",
    "datasets_dir = os.path.join(scratch_dir, 'GenerateMLDataset/data/')\n",
    "print(f'Dataset directory is: {datasets_dir}')\n",
    "datasets_dir = OrcaAnalysis().convert_path(datasets_dir)\n",
    "\n",
    "dataset_name = 'fragments_hopt_nmr.csv'\n",
    "\n",
    "nucprop = os.path.join(datasets_dir, dataset_name)\n",
    "nucprop_df = pd.read_csv(nucprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Molecule           Atom   x_coord   y_coord   z_coord  \\\n",
      "0  df_cut_4_n1_opt.xyz   Nucleus 7H :  1.004732  0.618235  0.399603   \n",
      "1  df_cut_4_n1_opt.xyz   Nucleus 8H : -0.479139  0.823720  0.426466   \n",
      "2  df_cut_4_n1_opt.xyz   Nucleus 9H : -1.139424  1.293590 -0.715278   \n",
      "3  df_cut_4_n1_opt.xyz  Nucleus 10H : -2.529680  1.410024 -0.731269   \n",
      "4  df_cut_4_n1_opt.xyz  Nucleus 11H : -3.272787  1.055261  0.391918   \n",
      "5  df_cut_4_n1_opt.xyz  Nucleus 12H : -2.626124  0.579825  1.530644   \n",
      "6  df_cut_4_n1_opt.xyz  Nucleus 13H : -1.235220  0.460846  1.547455   \n",
      "7  df_cut_4_n1_opt.xyz  Nucleus 14H :  1.553520  1.498202  0.765691   \n",
      "8  df_cut_4_n1_opt.xyz  Nucleus 19H :  1.284892 -0.237829  1.022092   \n",
      "9  df_cut_4_n1_opt.xyz  Nucleus 20H : -0.561879  1.500165 -1.613817   \n",
      "\n",
      "   sigma_iso  sigma_xx  sigma_yy  sigma_zz  dia_sigma_xx  ...  dia_sigma_zz  \\\n",
      "0      28.71     34.44     26.20     25.50         45.09  ...         20.37   \n",
      "1      28.66     33.20     27.90     24.88         24.68  ...         34.50   \n",
      "2      25.80     29.45     26.15     21.81         45.32  ...         30.01   \n",
      "3      25.71     21.87     27.98     27.28         45.53  ...         18.25   \n",
      "4      23.23     22.20     23.28     24.21         12.13  ...         40.98   \n",
      "5      25.80     21.81     28.17     27.42         45.81  ...         16.52   \n",
      "6      25.57     29.22     25.82     21.67         45.27  ...         27.78   \n",
      "7      28.84     33.28     28.23     25.01         24.29  ...         34.72   \n",
      "8      30.04     34.52     30.56     25.04         39.22  ...         22.11   \n",
      "9      30.01     34.81     30.26     24.97         41.30  ...         25.30   \n",
      "\n",
      "   para_sigma_xx  para_sigma_yy  para_sigma_zz  sigma_11  sigma_22  sigma_33  \\\n",
      "0         -12.17           3.32           5.17     25.50     26.20     34.44   \n",
      "1          -8.86          -2.88           2.09     24.88     27.90     33.20   \n",
      "2         -19.56           0.18          -7.79     21.81     26.15     29.45   \n",
      "3         -18.92          -4.64           4.48     21.87     27.28     27.98   \n",
      "4          10.96         -20.55         -16.79     22.20     23.28     24.21   \n",
      "5         -19.08          -4.78           6.15     21.81     27.42     28.17   \n",
      "6         -19.88          -0.62          -5.76     21.67     25.82     29.22   \n",
      "7           2.95          -8.94          -3.82     25.01     28.23     33.28   \n",
      "8          -4.83          -0.33           3.03     25.04     30.56     34.52   \n",
      "9          -6.83           5.68          -0.13     24.97     30.26     34.81   \n",
      "\n",
      "   s_tot_symmetry  span  skew  \n",
      "0               0  8.94 -0.84  \n",
      "1               0  8.32 -0.27  \n",
      "2               0  7.64  0.14  \n",
      "3               0  6.11  0.77  \n",
      "4               0  2.01  0.07  \n",
      "5               0  6.36  0.76  \n",
      "6               0  7.55  0.10  \n",
      "7               0  8.27 -0.22  \n",
      "8               0  9.48  0.16  \n",
      "9               0  9.84  0.08  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(nucprop_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Molecule  Atom   x_coord   y_coord   z_coord  sigma_iso  sigma_xx  \\\n",
      "0         0    83  1.004732  0.618235  0.399603      28.71     34.44   \n",
      "1         0    85 -0.479139  0.823720  0.426466      28.66     33.20   \n",
      "2         0    88 -1.139424  1.293590 -0.715278      25.80     29.45   \n",
      "3         0     2 -2.529680  1.410024 -0.731269      25.71     21.87   \n",
      "4         0     4 -3.272787  1.055261  0.391918      23.23     22.20   \n",
      "5         0     7 -2.626124  0.579825  1.530644      25.80     21.81   \n",
      "6         0     9 -1.235220  0.460846  1.547455      25.57     29.22   \n",
      "7         0    12  1.553520  1.498202  0.765691      28.84     33.28   \n",
      "8         0    26  1.284892 -0.237829  1.022092      30.04     34.52   \n",
      "9         0    32 -0.561879  1.500165 -1.613817      30.01     34.81   \n",
      "\n",
      "   sigma_yy  sigma_zz  dia_sigma_xx  ...  dia_sigma_zz  para_sigma_xx  \\\n",
      "0     26.20     25.50         45.09  ...         20.37         -12.17   \n",
      "1     27.90     24.88         24.68  ...         34.50          -8.86   \n",
      "2     26.15     21.81         45.32  ...         30.01         -19.56   \n",
      "3     27.98     27.28         45.53  ...         18.25         -18.92   \n",
      "4     23.28     24.21         12.13  ...         40.98          10.96   \n",
      "5     28.17     27.42         45.81  ...         16.52         -19.08   \n",
      "6     25.82     21.67         45.27  ...         27.78         -19.88   \n",
      "7     28.23     25.01         24.29  ...         34.72           2.95   \n",
      "8     30.56     25.04         39.22  ...         22.11          -4.83   \n",
      "9     30.26     24.97         41.30  ...         25.30          -6.83   \n",
      "\n",
      "   para_sigma_yy  para_sigma_zz  sigma_11  sigma_22  sigma_33  s_tot_symmetry  \\\n",
      "0           3.32           5.17     25.50     26.20     34.44               0   \n",
      "1          -2.88           2.09     24.88     27.90     33.20               0   \n",
      "2           0.18          -7.79     21.81     26.15     29.45               0   \n",
      "3          -4.64           4.48     21.87     27.28     27.98               0   \n",
      "4         -20.55         -16.79     22.20     23.28     24.21               0   \n",
      "5          -4.78           6.15     21.81     27.42     28.17               0   \n",
      "6          -0.62          -5.76     21.67     25.82     29.22               0   \n",
      "7          -8.94          -3.82     25.01     28.23     33.28               0   \n",
      "8          -0.33           3.03     25.04     30.56     34.52               0   \n",
      "9           5.68          -0.13     24.97     30.26     34.81               0   \n",
      "\n",
      "   span  skew  \n",
      "0  8.94 -0.84  \n",
      "1  8.32 -0.27  \n",
      "2  7.64  0.14  \n",
      "3  6.11  0.77  \n",
      "4  2.01  0.07  \n",
      "5  6.36  0.76  \n",
      "6  7.55  0.10  \n",
      "7  8.27 -0.22  \n",
      "8  9.48  0.16  \n",
      "9  9.84  0.08  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a LabelEncoder object\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Use the LabelEncoder object to transform the Species target variable\n",
    "nucprop_df['Molecule'] = label_encoder.fit_transform(nucprop_df['Molecule'])\n",
    "nucprop_df['Atom'] = label_encoder.fit_transform(nucprop_df['Atom'])\n",
    "\n",
    "print(nucprop_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.000000e+00  8.300000e+01  1.004732e+00 ...  0.000000e+00\n",
      "   8.940000e+00 -8.400000e-01]\n",
      " [ 0.000000e+00  8.500000e+01 -4.791390e-01 ...  0.000000e+00\n",
      "   8.320000e+00 -2.700000e-01]\n",
      " [ 0.000000e+00  8.800000e+01 -1.139424e+00 ...  0.000000e+00\n",
      "   7.640000e+00  1.400000e-01]\n",
      " ...\n",
      " [ 5.130000e+02  8.700000e+01 -4.337932e+00 ...  0.000000e+00\n",
      "   1.770700e+02 -6.000000e-02]\n",
      " [ 5.130000e+02  3.000000e+00 -4.687532e+00 ...  0.000000e+00\n",
      "   2.147300e+02 -2.000000e-02]\n",
      " [ 5.130000e+02  1.000000e+01  1.425015e+00 ...  0.000000e+00\n",
      "   9.723000e+01  2.000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "np_nucprop_df = nucprop_df.to_numpy()\n",
    "print(np_nucprop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data will contain all rows and the first 4 columns\n",
    "X_data = np_nucprop_df[:,0:21]\n",
    "\n",
    "# The output data will contain all rows and the last columns\n",
    "Y_data = np_nucprop_df[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.71,  28.66,  25.8 , ...,  64.56,  46.06, 210.16])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the data\n",
    "scaler.fit(X_data)\n",
    "\n",
    "# Transform the input data\n",
    "X_data = scaler.transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASSES = 3\n",
    "NB_FEATURES = 4\n",
    "\n",
    "# Create a sequential model, a simple linear stack of layers for Keras\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(keras.layers.Dense(128,                               # Number of nodes in the layer\n",
    "                              input_shape=(NB_FEATURES,),       # Number of input variables\n",
    "                              name='hidden_layer_1',            # Logical name\n",
    "                              activation='relu'))               # Activation function\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                              name='hidden_layer_2',\n",
    "                              activation='relu'))\n",
    "\n",
    "# Add the output layer with softmax activation\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='output_layer',\n",
    "                             activation='softmax'))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model meta-data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE=1\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=10\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=VERBOSE,\n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot accuracy of the model after each epoch.\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(5, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"iris_save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"iris_save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New input data\n",
    "prediction_input = [[6.6, 3. , 4.4, 1.4]]\n",
    "\n",
    "# Scale the input data with the same scaling model\n",
    "scaled_input = scaler.transform(prediction_input)\n",
    "\n",
    "# Get raw prediction probabilities\n",
    "raw_prediction = model.predict(scaled_input)\n",
    "print(\"Raw Prediction Output (Probabilities) :\" , raw_prediction)\n",
    "\n",
    "# Interpret the model output\n",
    "prediction = np.argmax(raw_prediction)\n",
    "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
