{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NONCOVToolbox: Step 2\n",
    "## Generate the datasets from the ORCA output files with @OrcaAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the OrcaAnalysis module of the NONCOVToolbox to postprocess the ORCA output files from DFT calculations and save data to csv pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary modules from the NONCOVToolbox src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pathlib as Path\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "#NONCOVHeader.print_header()\n",
    "\n",
    "# OrcaAnalysis module for postprocessing of DFT calculations\n",
    "from noncov import OrcaAnalysis\n",
    "\n",
    "# Functions to store data in dataframes\n",
    "from noncov import MachineLearning\n",
    "\n",
    "# Show performance and features of various NMR functions in module\n",
    "from noncov import NMRFunctions\n",
    "\n",
    "# Disable printing\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore printing\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory is: C:\\Users\\ettor\\Desktop\\NONCOV\\results\n",
      "Current scratch directory is: C:\\Users\\ettor\\Desktop\\NONCOV\\scratch\n",
      "Normalized path using os.path: C:/Users/ettor/Desktop/NONCOV/scratch\n"
     ]
    }
   ],
   "source": [
    "# Get work directory and scratch folder for the output data\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current work directory is: {current_dir}')\n",
    "\n",
    "scratch_dir = os.path.abspath(os.path.join('..', 'scratch'))\n",
    "print(f'Current scratch directory is: {scratch_dir}')\n",
    "scratch_dir = OrcaAnalysis().convert_path(scratch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preallocate two empty dataframes for ML applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory is: C:/Users/ettor/Desktop/NONCOV/scratch\\GenerateMLDataset/data/\n",
      "Normalized path using os.path: C:/Users/ettor/Desktop/NONCOV/scratch/GenerateMLDataset/data/\n",
      "Some files found in the directory, skipping... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check whether a database exists in your directory and create it if it doesnt\n",
    "datasets_dir = os.path.join(scratch_dir, 'GenerateMLDataset/data/')\n",
    "print(f'Dataset directory is: {datasets_dir}')\n",
    "datasets_dir = OrcaAnalysis().convert_path(datasets_dir)\n",
    "\n",
    "dataset_name = 'fragments_hopt_nmr.csv'\n",
    "\n",
    "if os.listdir(datasets_dir) == []:\n",
    "    print(\"No files found in the directory, creating datasets... \\n\")\n",
    "    \n",
    "    # Make the dataset for the individual NMR properties\n",
    "    MachineLearning().make_empty_nuc_prop_df(datasets_dir, dataset_name)\n",
    "else:\n",
    "    print(\"Some files found in the directory, skipping... \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display how the empty databases look like\n",
    "nucprop = os.path.join(datasets_dir, dataset_name)\n",
    "nucprop_df = pd.read_csv(nucprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Atom</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>z_coord</th>\n",
       "      <th>sigma_iso</th>\n",
       "      <th>sigma_xx</th>\n",
       "      <th>sigma_yy</th>\n",
       "      <th>sigma_zz</th>\n",
       "      <th>dia_sigma_xx</th>\n",
       "      <th>...</th>\n",
       "      <th>dia_sigma_zz</th>\n",
       "      <th>para_sigma_xx</th>\n",
       "      <th>para_sigma_yy</th>\n",
       "      <th>para_sigma_zz</th>\n",
       "      <th>sigma_11</th>\n",
       "      <th>sigma_22</th>\n",
       "      <th>sigma_33</th>\n",
       "      <th>s_tot_symmetry</th>\n",
       "      <th>span</th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Molecule, Atom, x_coord, y_coord, z_coord, sigma_iso, sigma_xx, sigma_yy, sigma_zz, dia_sigma_xx, dia_sigma_yy, dia_sigma_zz, para_sigma_xx, para_sigma_yy, para_sigma_zz, sigma_11, sigma_22, sigma_33, s_tot_symmetry, span, skew]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual nuclear properties\n",
    "nucprop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process ORCA calculations with @ORCAAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to the ORCA file you want to work with: \"C:\\Users\\ettor\\Desktop\\NONCOV\\tests\\nmr_ncs_comp.mpi8.out\"\n",
      "Normalized path using os.path: C:/Users/ettor/Desktop/NONCOV/tests/nmr_ncs_comp.mpi8.out\n"
     ]
    }
   ],
   "source": [
    "# Provide files you want to process as input \n",
    "orca_output = input(\"Enter the path to the ORCA file you want to work with: \")\n",
    "orca_output = OrcaAnalysis().convert_path(orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the head of the file for saving files later\n",
    "basename = os.path.basename(orca_output)\n",
    "outname = basename.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have calculated the following molecules: ['d_cut_0_n1_opt.xyz', 'df_cut_4_n1_opt.xyz', 'df_cut_4_n1_opt_disp_struct_0.xyz', 'df_cut_4_n1_opt_disp_struct_1.xyz', 'df_cut_4_n1_opt_disp_struct_10.xyz', 'df_cut_4_n1_opt_disp_struct_11.xyz', 'df_cut_4_n1_opt_disp_struct_12.xyz', 'df_cut_4_n1_opt_disp_struct_13.xyz', 'df_cut_4_n1_opt_disp_struct_14.xyz', 'df_cut_4_n1_opt_disp_struct_15.xyz', 'df_cut_4_n1_opt_disp_struct_16.xyz', 'df_cut_4_n1_opt_disp_struct_17.xyz', 'df_cut_4_n1_opt_disp_struct_18.xyz', 'df_cut_4_n1_opt_disp_struct_19.xyz', 'df_cut_4_n1_opt_disp_struct_2.xyz', 'df_cut_4_n1_opt_disp_struct_3.xyz', 'df_cut_4_n1_opt_disp_struct_4.xyz', 'df_cut_4_n1_opt_disp_struct_5.xyz', 'df_cut_4_n1_opt_disp_struct_6.xyz', 'df_cut_4_n1_opt_disp_struct_7.xyz', 'df_cut_4_n1_opt_disp_struct_8.xyz', 'df_cut_4_n1_opt_disp_struct_9.xyz', 'dw_cut_4_n1_1f_opt.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_0.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_1.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_10.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_11.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_12.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_13.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_14.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_15.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_16.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_17.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_18.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_19.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_2.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_3.xyz', 'dw_cut_4_n1_1f_opt_disp_struct_4.xyz']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the molecule names in the calculation, needed for ML later\n",
    "list_molecules = OrcaAnalysis().extract_molecule_names(orca_output)\n",
    "print(f'You have calculated the following molecules: {list_molecules}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ORCA jobs in file: 39\n",
      "\n",
      "Size of ORCA file is: 783.935089 MB\n",
      "\n",
      "Careful, you are working with a possibly large output file of several GB\n",
      "\n",
      "If using version controls consider setting up a .gitignore \n",
      "\n",
      "Careful, you are working with a '783.935089' KB large file..\n",
      "\n",
      "Set up a .gitignore or Git LFS before pushing to Git\n",
      "\n",
      "Level of theory for the NMR calculations is: Job started from odin1, running /scratch/bartalucci/nmr_ncs_comp__LJyf9K__121777/orca/orca\n",
      "\n",
      "Your output file will be now spilt into subfiles. \n",
      "\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job1.out\n",
      "Wrote job 1 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job1.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job2.out\n",
      "Wrote job 2 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job2.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job3.out\n",
      "Wrote job 3 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job3.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job4.out\n",
      "Wrote job 4 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job4.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job5.out\n",
      "Wrote job 5 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job5.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job6.out\n",
      "Wrote job 6 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job6.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job7.out\n",
      "Wrote job 7 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job7.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job8.out\n",
      "Wrote job 8 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job8.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job9.out\n",
      "Wrote job 9 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job9.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job10.out\n",
      "Wrote job 10 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job10.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job11.out\n",
      "Wrote job 11 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job11.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job12.out\n",
      "Wrote job 12 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job12.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job13.out\n",
      "Wrote job 13 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job13.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job14.out\n",
      "Wrote job 14 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job14.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job15.out\n",
      "Wrote job 15 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job15.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job16.out\n",
      "Wrote job 16 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job16.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job17.out\n",
      "Wrote job 17 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job17.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job18.out\n",
      "Wrote job 18 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job18.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job19.out\n",
      "Wrote job 19 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job19.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job20.out\n",
      "Wrote job 20 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job20.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job21.out\n",
      "Wrote job 21 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job21.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job22.out\n",
      "Wrote job 22 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job22.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job23.out\n",
      "Wrote job 23 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job23.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job24.out\n",
      "Wrote job 24 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job24.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job25.out\n",
      "Wrote job 25 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job25.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job26.out\n",
      "Wrote job 26 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job26.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job27.out\n",
      "Wrote job 27 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job27.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job28.out\n",
      "Wrote job 28 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job28.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job29.out\n",
      "Wrote job 29 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job29.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job30.out\n",
      "Wrote job 30 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job30.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job31.out\n",
      "Wrote job 31 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job31.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job32.out\n",
      "Wrote job 32 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job32.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job33.out\n",
      "Wrote job 33 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job33.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job34.out\n",
      "Wrote job 34 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job34.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job35.out\n",
      "Wrote job 35 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job35.out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job36.out\n",
      "Wrote job 36 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job36.out\n",
      "Output file path is C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job37.out\n",
      "Wrote job 37 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job37.out\n",
      "Wrote job 38 to C:/Users/ettor/Desktop/NONCOV/scratch\\OrcaAnalysis/split_orca_output/splitted_orca_job38.out\n",
      "ORCA output has been split into 38 sub files for further analysis\n"
     ]
    }
   ],
   "source": [
    "# Working with ORCA .out files\n",
    "\n",
    "# Count how many sequential calculations have been done\n",
    "n_jobs = OrcaAnalysis().count_jobs_number(orca_output)\n",
    "print(f'Number of ORCA jobs in file: {n_jobs}\\n')\n",
    "\n",
    "# Compute size of the .out file and suggest Git LFS \n",
    "size_orca_output = os.path.getsize(orca_output)\n",
    "size_orca_output = size_orca_output/1e6\n",
    "print(f'Size of ORCA file is: {size_orca_output} MB\\n')\n",
    "\n",
    "if n_jobs > 20:\n",
    "    print(f'Careful, you are working with a possibly large output file of several GB\\n')\n",
    "    print(f'If using version controls consider setting up a .gitignore \\n')\n",
    "\n",
    "if size_orca_output > 1:\n",
    "    print(f\"Careful, you are working with a '{size_orca_output}' KB large file..\\n\")\n",
    "    print(f'Set up a .gitignore or Git LFS before pushing to Git\\n')\n",
    "\n",
    "# Extract level of theory\n",
    "lot_out = OrcaAnalysis().extract_level_of_theory(orca_output)\n",
    "print(f'Level of theory for the NMR calculations is: {lot_out}\\n')\n",
    "\n",
    "# Split orca output in several subfiles for ease of handling (takes a while)\n",
    "if n_jobs > 2:\n",
    "    print('Your output file will be now spilt into subfiles. \\n')\n",
    "    OrcaAnalysis().split_orca_output(scratch_dir, orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for shielding tensor components\n",
    "S_dia = []\n",
    "S_para = []\n",
    "S_tot = []\n",
    "nuclear_identities = []\n",
    "mayer_bo = []\n",
    "nuc_coords = []\n",
    "\n",
    "# Extract NMR data from each splitted file\n",
    "for job_number in range (1, n_jobs): # split files = number of jobs\n",
    "        \n",
    "    blockPrint()\n",
    "    \n",
    "    # Path to the splitted outputs from the .out MPI8 file\n",
    "    orca_splitted_output = OrcaAnalysis().convert_path(os.path.join(scratch_dir, 'OrcaAnalysis/split_orca_output', f'splitted_orca_job{job_number}.out'))\n",
    "\n",
    "    # Extract CSA data\n",
    "    shielding_dia, shielding_para, shielding_tot, nucleus_info = OrcaAnalysis().extract_tensor_data(orca_splitted_output)\n",
    "\n",
    "    # Here include j coupling extraction\n",
    "    #-------------\n",
    "    \n",
    "    # Extract bond orders\n",
    "    bond_orders = OrcaAnalysis().extract_mayer_bond_order(orca_splitted_output)\n",
    "    \n",
    "    # Print the bond orders and their interacting nuclei\n",
    "    for nucleus, bonds in bond_orders.items():\n",
    "        print(f\"{nucleus}:\")\n",
    "        for interacting_nucleus, bond_order in bonds:\n",
    "            print(f\"  Bond with {interacting_nucleus}: {bond_order}\")\n",
    "    \n",
    "    enablePrint()\n",
    "    \n",
    "    coords = OrcaAnalysis().extract_xyz_coords(orca_splitted_output)\n",
    "    \n",
    "    # Append shielding tensor matrices (non-diagonalized) - all nuclei for each job iteration\n",
    "    S_dia.append(shielding_dia)\n",
    "    S_para.append(shielding_para)\n",
    "    S_tot.append(shielding_tot)\n",
    "    nuclear_identities.append(nucleus_info)\n",
    "    \n",
    "    # Append bond orders\n",
    "    mayer_bo.append(bond_orders)\n",
    "    \n",
    "    # Append coordinates\n",
    "    nuc_coords.append(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data that are not pairwise\n",
    "data = []\n",
    "\n",
    "# Loop through the number of jobs and get each molecule, each job has a different one\n",
    "for job_number in range(1, n_jobs):\n",
    "    molecule_name = list_molecules[job_number]\n",
    "    \n",
    "    # Process each job for S_tot\n",
    "    shielding_dict = S_tot[job_number]\n",
    "    if isinstance(shielding_dict, dict):\n",
    "        for nucleus_index, (nucleus_key, tensor) in enumerate(shielding_dict.items()):\n",
    "            shielding_tensor, s_iso, diagonal_mehring, eigenvals, eigenvecs, symmetry, span, skew = NMRFunctions().diagonalize_tensor(tensor)\n",
    "            \n",
    "            sigma_xx = eigenvals[0]\n",
    "            sigma_yy = eigenvals[1]\n",
    "            sigma_zz = eigenvals[2]\n",
    "            \n",
    "            sigma_11 = diagonal_mehring[0][0]\n",
    "            sigma_22 = diagonal_mehring[1][1]\n",
    "            sigma_33 = diagonal_mehring[2][2]\n",
    "            \n",
    "            # Extract coordinates and identities for the current nucleus\n",
    "            nuc_id = nuclear_identities[job_number][nucleus_index]\n",
    "            \n",
    "            # Handle different structures of nuc_coords\n",
    "            coords = nuc_coords[job_number][nucleus_index]\n",
    "            if len(coords) >= 3:\n",
    "                x_coord = coords[1]\n",
    "                y_coord = coords[2]\n",
    "                z_coord = coords[3]\n",
    "            else:\n",
    "                x_coord = y_coord = z_coord = None  \n",
    "\n",
    "            # Collect the data for this nucleus\n",
    "            row_data = {\n",
    "                'Molecule': molecule_name,\n",
    "                'Atom': nuc_id,\n",
    "                'x_coord': x_coord,\n",
    "                'y_coord': y_coord,\n",
    "                'z_coord': z_coord,\n",
    "                'sigma_iso': s_iso,\n",
    "                'sigma_xx': sigma_xx,\n",
    "                'sigma_yy': sigma_yy,\n",
    "                'sigma_zz': sigma_zz,\n",
    "                'dia_sigma_xx': None,  \n",
    "                'dia_sigma_yy': None,\n",
    "                'dia_sigma_zz': None,\n",
    "                'para_sigma_xx': None,  \n",
    "                'para_sigma_yy': None,\n",
    "                'para_sigma_zz': None,\n",
    "                'sigma_11' : sigma_11,\n",
    "                'sigma_22' : sigma_22,\n",
    "                'sigma_33' : sigma_33,\n",
    "                's_tot_symmetry' : symmetry,\n",
    "                'span' : span,\n",
    "                'skew' : skew\n",
    "            }\n",
    "            data.append(row_data)\n",
    "\n",
    "    # After collecting data from S_tot, update with data from S_dia\n",
    "    shielding_dict = S_dia[job_number]\n",
    "    if isinstance(shielding_dict, dict):\n",
    "        for nucleus_index, (nucleus_key, tensor) in enumerate(shielding_dict.items()):\n",
    "            dia_shielding_tensor, dia_s_iso, dia_diagonal_mehring, dia_eigenvals, dia_eigenvecs, dia_symmetry, dia_span, dia_skew = NMRFunctions().diagonalize_tensor(tensor)\n",
    "\n",
    "            dia_sigma_xx = dia_eigenvals[0]\n",
    "            dia_sigma_yy = dia_eigenvals[1]\n",
    "            dia_sigma_zz = dia_eigenvals[2]\n",
    "\n",
    "            # Update the existing row_data with dia_sigma values\n",
    "            for row in data:\n",
    "                if row['Molecule'] == molecule_name and row['Atom'] == nucleus_key:\n",
    "                    row.update({\n",
    "                        'dia_sigma_xx': dia_sigma_xx,\n",
    "                        'dia_sigma_yy': dia_sigma_yy,\n",
    "                        'dia_sigma_zz': dia_sigma_zz\n",
    "                    })\n",
    "\n",
    "    # After collecting data from S_dia, update with data from S_para\n",
    "    shielding_dict = S_para[job_number]\n",
    "    if isinstance(shielding_dict, dict):\n",
    "        for nucleus_index, (nucleus_key, tensor) in enumerate(shielding_dict.items()):\n",
    "            para_shielding_tensor, para_s_iso, para_diagonal_mehring, para_eigenvals, para_eigenvecs, para_symmetry, para_span, para_skew = NMRFunctions().diagonalize_tensor(tensor)\n",
    "            \n",
    "            para_sigma_xx = para_eigenvals[0]\n",
    "            para_sigma_yy = para_eigenvals[1]\n",
    "            para_sigma_zz = para_eigenvals[2]\n",
    "\n",
    "            # Update the existing row_data with para_sigma values\n",
    "            for row in data:\n",
    "                if row['Molecule'] == molecule_name and row['Atom'] == nucleus_key:\n",
    "                    row.update({\n",
    "                        'para_sigma_xx': para_sigma_xx,\n",
    "                        'para_sigma_yy': para_sigma_yy,\n",
    "                        'para_sigma_zz': para_sigma_zz\n",
    "                    })\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "datadf = pd.DataFrame(data)\n",
    "\n",
    "# Concatenate with the existing DataFrame\n",
    "nucprop_df = pd.concat([nucprop_df, datadf], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "nucprop_df.to_csv(nucprop, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "nucprop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
