{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the NONCOV Toolbox in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfig NONCOVToolbox Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "NONCOVHeader.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration file \n",
    "configdir = os.getcwd()\n",
    "configdir = os.path.abspath(os.path.join('..', 'config'))\n",
    "\n",
    "configs = os.path.join(configdir, 'configuration.yml')\n",
    "print(f'Change with care, configuration file is in:', configs)\n",
    "\n",
    "print('And looks like this...\\n')\n",
    "with open(configs,'r') as f:\n",
    "    config_file = f.read()\n",
    "    print(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get work directory and scratch folder for the output data\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current work directory is: {current_dir}')\n",
    "\n",
    "scratch_dir = os.path.abspath(os.path.join('..', 'scratch'))\n",
    "print(f'Current scratch directory is: {scratch_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: OrcaAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrcaAnalysis module for postprocessing of DFT calculations\n",
    "from noncov import OrcaAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide files you want to process as input \n",
    "# Example: \"D:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\tests\\data\\KLaL_cation_pi_RCCE_opt.mpi8.out\"\n",
    "orca_output = input(\"Enter the path to the ORCA file you want to work with: \")\n",
    "orca_output = OrcaAnalysis().convert_path(orca_output)\n",
    "scratch_dir = OrcaAnalysis().convert_path(scratch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with ORCA .out files\n",
    "\n",
    "# Count how many sequential calculations have been done\n",
    "n_jobs = OrcaAnalysis().count_jobs_number(orca_output)\n",
    "print(f'Number of ORCA jobs in file: {n_jobs}\\n')\n",
    "\n",
    "# Compute size of the .out file and suggest Git LFS \n",
    "size_orca_output = os.path.getsize(orca_output)\n",
    "size_orca_output = size_orca_output/1024\n",
    "print(f'Size of ORCA file is: {size_orca_output} KB\\n')\n",
    "\n",
    "if n_jobs > 20:\n",
    "    print(f'Careful, you are working with a possibly large output file of several GB\\n')\n",
    "    print(f'If using version controls consider setting up a .gitignore \\n')\n",
    "\n",
    "if size_orca_output > 1000:\n",
    "    print(f\"Careful, you are working with a '{size_orca_output}' KB large file..\\n\")\n",
    "    print(f'Set up a .gitignore or Git LFS before pushing to Git\\n')\n",
    "\n",
    "# Extract level of theory\n",
    "lot_out = OrcaAnalysis().extract_level_of_theory(orca_output)\n",
    "print(f'Level of theory for the NMR calculations is: {lot_out}\\n')\n",
    "\n",
    "# Split orca output in several subfiles for ease of handling (takes a while)\n",
    "if n_jobs > 2:\n",
    "    print('Your output file will be now spilt into subfiles. \\n')\n",
    "    OrcaAnalysis().split_orca_output(scratch_dir, orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the empirical boundaries ([A]) for various noncovalent interactions\n",
    "OrcaAnalysis().run_boundary_checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize displacement steps in Angstrom - need to find a clever way to do this\n",
    "displacement_steps_distance = [job * 0.25 for job in range(1,n_jobs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract the CSA tensor components for each nucleus at each distance iteration --- #\n",
    "\n",
    "# Initialize variables for shielding tensor components\n",
    "S_dia = []\n",
    "S_para = []\n",
    "S_tot = []\n",
    "nuclear_identities = []\n",
    "\n",
    "# Extract NMR data from each splitted file\n",
    "for job_number in range (1, n_jobs+1): # split files = number of jobs\n",
    "        \n",
    "    # Path to the splitted outputs from the .out MPI8 file\n",
    "    orca_splitted_output = os.path.join(scratch_dir, 'OrcaAnalysis/split_orca_output', f'splitted_orca_job{job_number}.out')\n",
    "\n",
    "    # Extract CSA data\n",
    "    shielding_dia, shielding_para, shielding_tot, nucleus_info = OrcaAnalysis().extract_csa_data(orca_splitted_output)\n",
    "    \n",
    "    # Append shielding tensor matrices (non-diagonalized)\n",
    "    S_dia.append(shielding_dia)\n",
    "    S_para.append(shielding_para)\n",
    "    S_tot.append(shielding_tot)\n",
    "    nuclear_identities.append(nucleus_info)\n",
    "    \n",
    "    # Plot the tensor values as a function of distance\n",
    "    plot_tensor_shielding(S_dia, S_para, S_tot, nuclear_identities, displacement_steps_distance, 0, 5, scratch_dir, job_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the molecule while its displaced, not interactive in Jupyter but interactive in VS Code\n",
    "from noncov import MolView\n",
    "\n",
    "# molecule = 'D:/PhD/Data/DFT/NONCOV/DFT_simulations/codes/scratch/test_structs/benzene_H2O.xyz'\n",
    "molecule = 'C:/Users/ettor/Desktop/NONCOV/scratch/test_structs/benzene_H2O.xyz'\n",
    "\n",
    "MolView().plot_3d_molecule(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot euler angles and rotated tensor\n",
    "tensor_pas = np.diag([1.0, 2.0, 3.0])  # Diagonal tensor in PAS\n",
    "alpha, beta, gamma = 30, 45, 60  # Euler angles in degrees\n",
    "MolView(). plot_3D_tensors_and_axes(tensor_pas, alpha, beta, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: NMRFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "# Show performance and features of various NMR functions in module\n",
    "from noncov import NMRFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------- #\n",
      "# TENSOR DIAGONALIZATION FUNCTION HAS BEEN REQUESTED #\n",
      "\n",
      "\n",
      "Shielding Tensor is: \n",
      "[[ -5.9766 -65.5206  -9.5073]\n",
      " [-60.302  -23.0881 -28.2399]\n",
      " [-10.8928 -25.2372  56.277 ]]\n",
      "Proceeding to transposing...\n",
      "\n",
      "Transposed matrix is: \n",
      "[[ -5.9766 -60.302  -10.8928]\n",
      " [-65.5206 -23.0881 -25.2372]\n",
      " [ -9.5073 -28.2399  56.277 ]]\n",
      "Proceeding to symmetrization...\n",
      "\n",
      "Symmetric tensor is: \n",
      "[[ -5.9766  -62.9113  -10.20005]\n",
      " [-62.9113  -23.0881  -26.73855]\n",
      " [-10.20005 -26.73855  56.277  ]]\n",
      "\n",
      "Antisymmetric tensor is. \n",
      "[[ 0.      -2.6093   0.69275]\n",
      " [ 2.6093   0.      -1.50135]\n",
      " [-0.69275  1.50135  0.     ]]\n",
      "\n",
      "Since antisymmetric part does not contribute to observable, skipping...\n",
      "\n",
      "Proceeding to diagonalization...\n",
      "\n",
      "Eigenvalues are: [-83.17  43.79  66.59], Eigenvectors are: \n",
      "[[ 0.65  0.76  0.32]\n",
      " [ 0.74 -0.52 -0.47]\n",
      " [ 0.18 -0.39  0.82]]\n",
      "\n",
      "Proceeding to ordering eigenvalues and eigenvectors...\n",
      "\n",
      "Magnitude-based ordering of eigenvalues is: \n",
      "[ 43.79  66.59 -83.17] \n",
      " and of eigenvectors is: \n",
      "[[ 0.76  0.32  0.65]\n",
      " [-0.52 -0.47  0.74]\n",
      " [-0.39  0.82  0.18]].\n",
      "Proceeding to diagonalization...\n",
      "\n",
      "Diagonalized tensor is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "Proceeding to compute isotropic shift...\n",
      "\n",
      "Isotropic shift is: 9.07 ppm\n",
      "Proceeding to Haberlen ordering...\n",
      "\n",
      "Diagonal tensor in Haberlen order is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "\n",
      "where:\n",
      " σ_XX:-83.17 \n",
      " σ_YY:43.79 \n",
      " σ_ZZ:66.59\n",
      "Proceeding to Mehring ordering...\n",
      "\n",
      "Diagonal tensor in Mehring order is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "\n",
      "where:\n",
      " σ_11:-83.17 \n",
      " σ_22:43.79 \n",
      " σ_33:66.59 \n",
      "\n",
      "Proceeding to shielding tensor symmetry analysis...\n",
      "\n",
      "Symmetry of the tensor based on eigenvals count is: 0\n",
      "\n",
      "which means that the tensor is symmetric\n",
      "The tensor has no obvious eigenvalue symmetry.\n",
      "\n",
      "The tensor is not symmetric (S != S^T).\n",
      "\n",
      "Checking for rotational symmetry:\n",
      "\n",
      "Eigenvector row 1: [0.65 0.74 0.18]\n",
      "Eigenvector row 2: [ 0.76 -0.52 -0.39]\n",
      "Eigenvector row 3: [ 0.32 -0.47  0.82]\n",
      "180 degrees rotation results in the tensor: \n",
      "[[ 56.277  -25.2372 -10.8928]\n",
      " [-28.2399 -23.0881 -60.302 ]\n",
      " [ -9.5073 -65.5206  -5.9766]]\n",
      "\n",
      "Rotational symmetry is: \n",
      "False\n",
      "\n",
      "Proceeding...\n",
      "\n",
      "Call tensor_to_euler for Euler angles extraction from eigenvectors...\n",
      "\n",
      "# -------------------------------------------------- #\n"
     ]
    }
   ],
   "source": [
    "# Test random tensor\n",
    "xx =-5.9766\n",
    "xy =-65.5206\n",
    "xz =-9.5073\n",
    "yx =-60.3020\n",
    "yy =-23.0881\n",
    "yz =-28.2399\n",
    "zx =-10.8928\n",
    "zy =-25.2372\n",
    "zz =56.277\n",
    "\n",
    "# Diagonalize tensor\n",
    "shielding_tensor, s_iso, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(xx, xy, xz, yx, yy, yz, zx, zy, zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random symmetric tensor for tests:   \n",
    "xx =0.745\n",
    "xy =0.524\n",
    "xz =0.642\n",
    "yx =0.524\n",
    "yy =0.147\n",
    "yz =0.483\n",
    "zx =0.642\n",
    "zy =0.483\n",
    "zz =0.255\n",
    "\n",
    "# Diagonalize tensor\n",
    "shielding_tensor, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(xx, xy, xz, yx, yy, yz, zx, zy, zz)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to Euler angles\n",
    "mode = 'AZYZ'\n",
    "order = 'Ascending'\n",
    "alpha, beta, gamma, tensor_pas = NMRFunctions().tensor_to_euler(shielding_tensor, eigenvals, eigenvecs, symmetry, mode, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate equivalent sets of angles\n",
    "NMRFunctions().EqEulerSet(alpha,beta,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolecularGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(molecule_path):\n",
    "\n",
    "    mol_graph = MolecularGraph()\n",
    "\n",
    "    # Parse the XYZ file\n",
    "    atom_types, coordinates = mol_graph.parse_xyz(molecule_path)\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    distances = mol_graph.calculate_distances(coordinates)\n",
    "    \n",
    "    # Detect covalent bonds\n",
    "    covalent_bonds = mol_graph.detect_bonds(atom_types, distances)\n",
    "    \n",
    "    # Detect non-covalent interactions\n",
    "    noncovalent_interactions = mol_graph.detect_noncovalent_interactions(atom_types, distances)\n",
    "    \n",
    "    # Build the molecular graph\n",
    "    #mol_graph = mol_graph.build_molecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "    \n",
    "    # Visualize the molecular graph\n",
    "    #mol_graph.draw()\n",
    "\n",
    "    # Plots \n",
    "    mol_graph.plot_bond_dist_matrix(covalent_bonds, distances, atom_types)\n",
    "    mol_graph.plot_noncov_distance_map(noncovalent_interactions, atom_types)\n",
    "\n",
    "    # Build different graphs\n",
    "    covalent_bonds_graph = mol_graph.build_covalent_bonds_graph(atom_types, coordinates, covalent_bonds)\n",
    "    intramolecular_graph = mol_graph.build_intramolecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "    intermolecular_graph = mol_graph.build_intermolecular_graph(atom_types, coordinates, noncovalent_interactions)\n",
    "\n",
    "    # Draw subplots while preserving atom positions\n",
    "    mol_graph.draw_subplots(covalent_bonds_graph, intramolecular_graph, intermolecular_graph, coordinates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold = 1.6\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current working directory is: {current_dir}')\n",
    "#molecule = os.path.join(current_dir, 'scratch/test_structs/caffeine.xyz')\n",
    "\n",
    "molecule = 'D:/PhD/Data/DFT/NONCOV/DFT_simulations/codes/scratch/test_structs/benzene_H2O.xyz'\n",
    "\n",
    "main(molecule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: DistanceScanner & RotationScanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH RELATIVE PATHS \n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# LOGS AND ERRORS\n",
    "error_log_file = 'error_log_file.txt' # to finish\n",
    "log_file = 'log_file.txt' # to finish\n",
    "\n",
    "\n",
    "# START TIMER: COMPUTE EFFECTIVE WALL TIME\n",
    "start = timer() # this is not in [sec] i think\n",
    "\n",
    "# SECTON: MAIN\n",
    "def main():\n",
    "\n",
    "    # Relative paths\n",
    "    start_structure = os.path.join(current_dir, 'input_structures/KLaL_cation_pi_RCCE_opt_NICS.xyz')\n",
    "    centroid_out = os.path.join(current_dir, 'centroid_output/centroid_file.xyz')\n",
    "    input_file = os.path.join(current_dir, 'input_file/input_file.txt')\n",
    "\n",
    "    # Read xyz file: this should be either a fully optimized geometry or one with relaxed H\n",
    "    coordinates, atom_identities = read_atomic_coord(start_structure)\n",
    "    print(f'Starting coordinates: {coordinates}')\n",
    "    print(f'Atom identities: {atom_identities}')\n",
    "\n",
    "    # Assign coordinates to molecular fragments, check nomenclature of your atoms in avogadro or any other molecular graphics soft\n",
    "    coords1, coords2 = assign_molecule_fragments(coordinates, input_file)\n",
    "\n",
    "    # Concatenate coordinates for k-means clustering\n",
    "    all_coords = np.concatenate((coords1, coords2), axis=0)\n",
    "    # print(f'All coords: {all_coords}')\n",
    "\n",
    "    # Count how many fragments you have defined in the input file, important for accurate K-means clustering\n",
    "    n_fragments = count_fragments(input_file)\n",
    "    print(f\"Number of '$fragment' occurrences: {n_fragments}\")\n",
    "\n",
    "    # Perform k-means clustering to compute centroids\n",
    "    kmeans = KMeans(n_clusters=n_fragments) # K-means clusters = number of centroids = number of fragments\n",
    "    kmeans.fit(all_coords)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Compute centroids for each fragment\n",
    "    fragment_centroids = calculate_centroids([coords1, coords2])\n",
    "\n",
    "    # Write centroid coordinates to file\n",
    "    write_centroids(centroid_out, fragment_centroids)\n",
    "    print(f'Centroid coordinates: {fragment_centroids}')\n",
    "\n",
    "    # Calculate displacement direction (line connecting centroids)\n",
    "    displacement_direction = centroids[1] - centroids[0]\n",
    "    displacement_direction /= np.linalg.norm(displacement_direction)\n",
    "    print(f'Displacement direction:{displacement_direction}')\n",
    "\n",
    "    # Read displacement step size from input file\n",
    "    displacement_step = None\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        read_displacement = False\n",
    "        for line in lines:\n",
    "            if read_displacement:\n",
    "                displacement_values = line.strip().split()\n",
    "                if displacement_values:\n",
    "                    displacement_step = float(displacement_values[0])\n",
    "                    break\n",
    "            elif line.strip() == \"$displacement\":\n",
    "                read_displacement = True\n",
    "\n",
    "    if displacement_step is None:\n",
    "        print('ERROR: displacement step size not found in input file, please specify it! Syntax => $displacement + number')\n",
    "        return\n",
    "    print(f'Displacement step is: {displacement_step}') # please doublecheck that it is the same value you defined in the input\n",
    "\n",
    "    # Displace the first fragment iteratively and save each structure\n",
    "    displaced_fragment_coords = coords1.copy()  # Make a copy of the original coordinates of the fragment that is displaced\n",
    "    print(f'Original coordinates displaced fragment:', displaced_fragment_coords)\n",
    "\n",
    "    # Initialize the coordinates for the fixed fragment (e.g., coords2)\n",
    "    coords_fixed = coords2.copy() # make a copy of the fixed fragment coordinates to append to the displaced ones\n",
    "    print(f'Original coordinates fixed fragment:', coords_fixed)\n",
    "\n",
    "    all_displaced_fragment_coords = [displaced_fragment_coords]  # List to store all displaced structures\n",
    "\n",
    "    # Combine displaced coordinates with original ones\n",
    "    all_combined_coords = [np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)]  # List to store all combined structures\n",
    "\n",
    "    fragment_centroids = [fragment_centroids[0]]  # List to store all centroids\n",
    "\n",
    "    # Dissociation limit NEED AT LEAST 40 OF THEM MINIMUM\n",
    "    diss_lim = 50 # change with the output value in agnstrom from func(dissociation_limit)\n",
    "\n",
    "    for i in range(1, diss_lim):  # Iterate 50 times (adjust the number as needed) put this as to be the dissociation limit of each DFT run\n",
    "        \n",
    "        displacement_vector = [] \n",
    "\n",
    "        # Compute new set of coordinates for displaced fragments, change $displacement value in input file to tune the displacement\n",
    "        displaced_fragment_coords = displace_fragment(coords1, displacement_direction, displacement_step, i)\n",
    "        #print(f'Displaced fragment coord is: {displaced_fragment_coords}')\n",
    "\n",
    "        combined_coords = np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)\n",
    "        all_combined_coords.append(combined_coords)\n",
    "\n",
    "        # Update centroids for the displaced structure\n",
    "        fragment_centroid = calculate_centroids([displaced_fragment_coords])\n",
    "        fragment_centroids.append(fragment_centroid[0])\n",
    "        print(f'Updated centroids:', fragment_centroid)\n",
    "\n",
    "        # Write displaced structure to file\n",
    "        output_file = Path(os.path.join(current_dir, f'displaced_structures/displaced_structure_{i}.xyz'))\n",
    "        write_displaced_xyz_file(output_file, coords_fixed, displaced_fragment_coords, atom_identities)\n",
    "\n",
    "        all_displaced_fragment_coords.append(displaced_fragment_coords)\n",
    "\n",
    "        # Compute distance between the fixed fragment centroid and all the atoms from the displaced fragment\n",
    "        centroid_to_displaced_distance = compute_distance_from_centroid(displaced_fragment_coords, centroids)\n",
    "        print(f'Distance between displaced coordinates and centroid is: {centroid_to_displaced_distance}')\n",
    "\n",
    "        # Write distances to file - needed for DFT calculations outputs\n",
    "        distance_output_file = Path(os.path.join(current_dir, f'distance_files/distances_structures_{i}.xyz'))\n",
    "        write_distances_file(distance_output_file, displaced_fragment_coords, centroid_to_displaced_distance, atom_identities, displacement_step)\n",
    "\n",
    "\n",
    "    # Plot initial topology for molecular fragments and centroids\n",
    "    fig = plot_starting_molecular_fragments(coords1, coords2, centroids)\n",
    "\n",
    "    # Generate colors for the plots based on displacement iteration\n",
    "    num_iterations = len(all_displaced_fragment_coords)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 1.0, num_iterations))\n",
    "\n",
    "    # Plot displaced molecular fragments and centroids\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot original fragments and centroids\n",
    "    ax.scatter(coords1[:, 0], coords1[:, 1], coords1[:, 2], color=colors[0], label='Molecule 1 (Original)')\n",
    "    ax.scatter(coords2[:, 0], coords2[:, 1], coords2[:, 2], color=colors[0], label='Molecule 2 (Original)')\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], color=colors[0], marker='x', s=100, label='Centroids (Original)')\n",
    "\n",
    "    # Plot displaced fragments and centroids\n",
    "    for i, displaced_coords in enumerate(all_displaced_fragment_coords[1:], start=1):\n",
    "        color = colors[i]\n",
    "        label = f'Iteration {i}'\n",
    "        ax.scatter(displaced_coords[:, 0], displaced_coords[:, 1], displaced_coords[:, 2], color=color, label=label)\n",
    "        ax.scatter(fragment_centroids[i][0], fragment_centroids[i][1], fragment_centroids[i][2], color=color, marker='x', s=100, label=f'Centroids ({label})')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # END TIMER: STOP TIMER AND PRINT\n",
    "    elapsed_time = timer() - start  # in seconds\n",
    "    print(f'Elapsed time for the code to run is: {elapsed_time}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: GenerateMLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "\n",
    "# current_dir = os.getcwd()\n",
    "# print(f'Current working directory is: {current_dir}')\n",
    "\n",
    "# root_directory = os.path.join(current_dir, 'Machine_learning/raw')\n",
    "# print(f'Dataset root directory is: {root_directory}')\n",
    "\n",
    "# output_csv_path = os.path.join(current_dir, 'Machine_learning/datasets/model_structures/test.csv')\n",
    "# print(f'Dataset directory is: {output_csv_path}')\n",
    "\n",
    "# generate_dataset = GenerateMLDataset(root_directory, output_csv_path)\n",
    "# generate_dataset.search_files()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: AminoStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# toolbox = NONCOVToolbox()\n",
    "# amino_stats = toolbox.AminoStat()\n",
    "\n",
    "# # Example usage\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# protein_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spidersilks.txt')\n",
    "# spaced_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spaced_spidersilks.txt')\n",
    "# count_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_count.txt')\n",
    "# plot_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_statistics.pdf')\n",
    "\n",
    "# #amino_stats = AminoStat()\n",
    "\n",
    "# amino_stats.space_prot_seq(protein_sequence, spaced_sequence)\n",
    "# amino_stats.count_amino_acids(spaced_sequence, count_file)\n",
    "# amino_stats.plot_amino_acid_statistics(count_file, plot_file)\n",
    "\n",
    "# amino_stats.define_protein_domains()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
