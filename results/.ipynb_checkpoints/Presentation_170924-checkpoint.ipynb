{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noncovalent interactions and NMR observables\n",
    "## Some ideas for the NONCOV Toolbox in Python\n",
    "\n",
    "### Ettore Bartalucci, Progress Report 17.09.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noncovalent interactions can be experimentally detected from NMR parameters (e.g. changes in $\\sigma_{iso}$)\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, some of the questions that are yet to be answered are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How sensitive are individual nuclei to NCIs?\n",
    "* How is the response of each nucleus to different NCI? e.g. are there preferential ones?\n",
    "* Whats the geometric response of NMR observables undergoing NCIs?\n",
    "* Is it possible to separate the contributions of each NCIs to a selected observable of interest?\n",
    "* BONUS: Can we machine learn these trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project works thanks to:\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"oreilymeme1.png\" width=\"350\" />\n",
    "  <img src=\"oreilymeme2.png\" width=\"350\" /> \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "nci[\"Choose NCI\n",
    "    fragments\"] --> dft(\"Relax structures\n",
    "                        @DFT\")\n",
    "    \n",
    "    dft -->|HPC@MPI| crest[\"in-silico \n",
    "                            CREST/CENSO l.e.c.\"]\n",
    "    dft -->|StructureModifier| displace[Displace fragments]\n",
    "    dft -->|StructureModifier| rotate[Rotate Fragments]\n",
    "\n",
    "    crest --> nmr[\"Compute \n",
    "                    NMR parameters\"]\n",
    "    displace --> nmr[\"Compute \n",
    "                    NMR parameters\"]\n",
    "    rotate --> nmr[\"Compute \n",
    "                    NMR parameters\"]\n",
    "\n",
    "    nmr -->postproc[\"General\n",
    "                    postprocessing\"]\n",
    "    postproc --> sigma[Shielding Tensor]\n",
    "    postproc --> j[J coupling Tensor]\n",
    "    postproc --> meyer[Meyer B.O.]\n",
    "    postproc --> else[Anything else?]\n",
    "\n",
    "    sigma --> ml[Input for ML dataframe]\n",
    "    j --> ml[Input for ML dataframe]\n",
    "    meyer --> ml[Input for ML dataframe]\n",
    "    else --> ml[Input for ML dataframe]\n",
    "\n",
    "    sigma --> view[Plots]\n",
    "    j --> view[Plots]\n",
    "    meyer --> view[Plots]\n",
    "    else --> view[Plots]\n",
    "\n",
    "    ml --> predictions[\"Predict NCI\n",
    "                        contribution %\n",
    "                        to NMR parameters\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of datasets for Machine learning:\n",
    "\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "nuc[\"Single-nucleus\n",
    "    properties\"] --> shift[e.g. shielding tensor] --> 1[nuc_prop_nmr_observables] \n",
    "    \n",
    "pair[\"Pairwise\n",
    "    properties\"] --> coup[e.g. J coupling] --> 2[pairwise_nuc_prop_nmr_observables] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfig NONCOVToolbox Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pathlib as Path\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "#NONCOVHeader.print_header()\n",
    "\n",
    "# Pre work on molecular geometries\n",
    "from noncov import StructureModifier\n",
    "\n",
    "# OrcaAnalysis module for postprocessing of DFT calculations\n",
    "from noncov import OrcaAnalysis\n",
    "\n",
    "# Graph molecular representations\n",
    "from noncov import MolecularGraph\n",
    "\n",
    "# Functions to store data in dataframes\n",
    "from noncov import MachineLearning\n",
    "\n",
    "# Show performance and features of various NMR functions in module\n",
    "from noncov import NMRFunctions\n",
    "\n",
    "# Display the molecule while its displaced, not yet interactive in Jupyter but interactive in VS Code\n",
    "from noncov import MolView\n",
    "\n",
    "# Disable printing\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore printing\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get configuration file \n",
    "configdir = os.getcwd()\n",
    "configdir = os.path.abspath(os.path.join('..', 'config'))\n",
    "\n",
    "configs = os.path.join(configdir, 'configuration.yml')\n",
    "print(f'Change with care, configuration file is in:', configs)\n",
    "\n",
    "print('And looks like this...\\n')\n",
    "with open(configs,'r') as f:\n",
    "    config_file = f.read()\n",
    "    print(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get work directory and scratch folder for the output data\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current work directory is: {current_dir}')\n",
    "\n",
    "scratch_dir = os.path.abspath(os.path.join('..', 'scratch'))\n",
    "print(f'Current scratch directory is: {scratch_dir}')\n",
    "scratch_dir = OrcaAnalysis().convert_path(scratch_dir)\n",
    "\n",
    "mol_dir = os.path.join(scratch_dir, 'test_structs/benzene_H2O.xyz')\n",
    "print(f'Current molecule directory is: {mol_dir}')\n",
    "mol_dir = OrcaAnalysis().convert_path(mol_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: GenerateMLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY IF YOU NEVER CREATED THE EMPTY DATASET BEFORE OTHERWISE IS OVERWRITING\n",
    "datasets_dir = os.path.join(scratch_dir, 'GenerateMLDataset/data/')\n",
    "print(f'Dataset directory is: {datasets_dir}')\n",
    "datasets_dir = OrcaAnalysis().convert_path(datasets_dir)\n",
    "\n",
    "if os.listdir(datasets_dir) == []:\n",
    "    print(\"No files found in the directory, creating datasets... \\n\")\n",
    "    # Make the dataset for the pairwise NMR properties\n",
    "    MachineLearning().make_empty_pairwise_prop_df(datasets_dir)\n",
    "    \n",
    "    # Make the dataset for the individual NMR properties\n",
    "    MachineLearning().make_empty_nuc_prop_df(datasets_dir)\n",
    "else:\n",
    "    print(\"Some files found in the directory, skipping... \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display how the empty databases look like\n",
    "nucprop = os.path.join(datasets_dir, 'nuc_prop_nmr_observables.csv')\n",
    "nucprop_df = pd.read_csv(nucprop)\n",
    "\n",
    "pw_nucprop = os.path.join(datasets_dir, 'pairwise_nuc_prop_nmr_observables.csv')\n",
    "pw_nucprop_df = pd.read_csv(pw_nucprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucprop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_nucprop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module: StructureModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative paths\n",
    "start_structure = os.path.join(scratch_dir, 'StructureModifier/input_structures/KLaL_cation_pi_RCCE_opt_NICS.xyz')\n",
    "centroid_out = os.path.join(scratch_dir, 'StructureModifier/centroid_output/centroid_file.xyz')\n",
    "input_file = os.path.join(scratch_dir, 'StructureModifier/input_file/input_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(input_file, 'r') as file:\n",
    "    input_content = file.read()\n",
    "    print(input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read xyz file: this should be either a fully optimized geometry or one with relaxed H\n",
    "coordinates, atom_identities = StructureModifier().read_atomic_coord(start_structure)\n",
    "#print(f'Starting coordinates: {coordinates}')\n",
    "#print(f'Atom identities: {atom_identities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign coordinates to molecular fragments, check nomenclature of your atoms in avogadro or any other molecular graphics soft\n",
    "coords1, coords2 = StructureModifier().assign_molecule_fragments(coordinates, input_file)\n",
    "\n",
    "# Concatenate coordinates for k-means clustering\n",
    "all_coords = np.concatenate((coords1, coords2), axis=0)\n",
    "# print(f'All coords: {all_coords}')\n",
    "\n",
    "# Count how many fragments you have defined in the input file, important for accurate K-means clustering\n",
    "n_fragments = StructureModifier().count_fragments(input_file)\n",
    "#print(f\"Number of '$fragment': {n_fragments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-means clustering to compute centroids\n",
    "kmeans = KMeans(n_clusters=n_fragments) # K-means clusters = number of centroids = number of fragments\n",
    "kmeans.fit(all_coords)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute centroids for each fragment\n",
    "fragment_centroids = StructureModifier().calculate_centroids([coords1, coords2])\n",
    "\n",
    "# Write centroid coordinates to file\n",
    "StructureModifier().write_centroids(centroid_out, fragment_centroids)\n",
    "#print(f'Centroid coordinates: {fragment_centroids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate displacement direction (line connecting centroids)\n",
    "displacement_direction = centroids[1] - centroids[0]\n",
    "displacement_direction /= np.linalg.norm(displacement_direction)\n",
    "#print(f'Displacement direction:{displacement_direction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read displacement step size from input file\n",
    "displacement_step = None\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    read_displacement = False\n",
    "    for line in lines:\n",
    "        if read_displacement:\n",
    "            displacement_values = line.strip().split()\n",
    "            if displacement_values:\n",
    "                displacement_step = float(displacement_values[0])\n",
    "                break\n",
    "        elif line.strip() == \"$displacement\":\n",
    "            read_displacement = True\n",
    "\n",
    "if displacement_step is None:\n",
    "    print('ERROR: displacement step size not found in input file, please specify it! Syntax => $displacement + number')\n",
    "print(f'Displacement step is: {displacement_step} Angstroem') # please doublecheck that it is the same value you defined in the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displace the first fragment iteratively and save each structure\n",
    "displaced_fragment_coords = coords1.copy()  # Make a copy of the original coordinates of the fragment that is displaced\n",
    "#print(f'Original coordinates displaced fragment:', displaced_fragment_coords)\n",
    "\n",
    "# Initialize the coordinates for the fixed fragment (e.g., coords2)\n",
    "coords_fixed = coords2.copy() # make a copy of the fixed fragment coordinates to append to the displaced ones\n",
    "#print(f'Original coordinates fixed fragment:', coords_fixed)\n",
    "\n",
    "all_displaced_fragment_coords = [displaced_fragment_coords]  # List to store all displaced structures\n",
    "\n",
    "# Combine displaced coordinates with original ones\n",
    "all_combined_coords = [np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)]  # List to store all combined structures\n",
    "\n",
    "fragment_centroids = [fragment_centroids[0]]  # List to store all centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissociation limit NEED AT LEAST 40 OF THEM MINIMUM\n",
    "diss_lim = 50 # change with the output value in agnstrom from func(dissociation_limit)\n",
    "\n",
    "for i in range(1, diss_lim):  # Iterate 50 times (adjust the number as needed) put this as to be the dissociation limit of each DFT run\n",
    "\n",
    "    displacement_vector = [] \n",
    "\n",
    "    # Compute new set of coordinates for displaced fragments, change $displacement value in input file to tune the displacement\n",
    "    displaced_fragment_coords = StructureModifier().displace_fragment(coords1, displacement_direction, displacement_step, i)\n",
    "    #print(f'Displaced fragment coord is: {displaced_fragment_coords}')\n",
    "\n",
    "    combined_coords = np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)\n",
    "    all_combined_coords.append(combined_coords)\n",
    "\n",
    "    # Update centroids for the displaced structure\n",
    "    fragment_centroid = StructureModifier().calculate_centroids([displaced_fragment_coords])\n",
    "    fragment_centroids.append(fragment_centroid[0])\n",
    "    print(f'Updated centroids:', fragment_centroid)\n",
    "    \n",
    "    # Write displaced structure to file\n",
    "    output_file = os.path.join(scratch_dir, f'StructureModifier/displaced_structures/displaced_structure_{i}.xyz')\n",
    "    StructureModifier().write_displaced_xyz_file(output_file, coords_fixed, displaced_fragment_coords, atom_identities)\n",
    "\n",
    "    all_displaced_fragment_coords.append(displaced_fragment_coords)\n",
    "\n",
    "    # Compute distance between the fixed fragment centroid and all the atoms from the displaced fragment\n",
    "    centroid_to_displaced_distance = StructureModifier().compute_distance_from_centroid(displaced_fragment_coords, centroids)\n",
    "    print(f'Distance between displaced coordinates and centroid is: {centroid_to_displaced_distance}')\n",
    "\n",
    "    # Write distances to file - needed for DFT calculations outputs\n",
    "    distance_output_file = os.path.join(scratch_dir, f'StructureModifier/distance_files/distances_structures_{i}.xyz')\n",
    "\n",
    "    StructureModifier().write_distances_file(distance_output_file, displaced_fragment_coords, centroid_to_displaced_distance, atom_identities, displacement_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial topology for molecular fragments and centroids\n",
    "fig = StructureModifier().plot_starting_molecular_fragments(coords1, coords2, centroids)\n",
    "\n",
    "# Generate colors for the plots based on displacement iteration\n",
    "num_iterations = len(all_displaced_fragment_coords)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 1.0, num_iterations))\n",
    "\n",
    "# Plot displaced molecular fragments and centroids\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot original fragments and centroids\n",
    "ax.scatter(coords1[:, 0], coords1[:, 1], coords1[:, 2], color=colors[0], label='Molecule 1 (Original)')\n",
    "ax.scatter(coords2[:, 0], coords2[:, 1], coords2[:, 2], color=colors[0], label='Molecule 2 (Original)')\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], color=colors[0], marker='x', s=100, label='Centroids (Original)')\n",
    "\n",
    "# Plot displaced fragments and centroids\n",
    "for i, displaced_coords in enumerate(all_displaced_fragment_coords[1:], start=1):\n",
    "    color = colors[i]\n",
    "    label = f'Iteration {i}'\n",
    "    ax.scatter(displaced_coords[:, 0], displaced_coords[:, 1], displaced_coords[:, 2], color=color, label=label)\n",
    "    ax.scatter(fragment_centroids[i][0], fragment_centroids[i][1], fragment_centroids[i][2], color=color, marker='x', s=100, label=f'Centroids ({label})')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: OrcaAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide files you want to process as input \n",
    "# Example: \"D:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\tests\\data\\KLaL_cation_pi_RCCE_opt.mpi8.out\"\n",
    "orca_output = input(\"Enter the path to the ORCA file you want to work with: \")\n",
    "orca_output = OrcaAnalysis().convert_path(orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with ORCA .out files\n",
    "\n",
    "# Count how many sequential calculations have been done\n",
    "n_jobs = OrcaAnalysis().count_jobs_number(orca_output)\n",
    "print(f'Number of ORCA jobs in file: {n_jobs}\\n')\n",
    "\n",
    "# Compute size of the .out file and suggest Git LFS \n",
    "size_orca_output = os.path.getsize(orca_output)\n",
    "size_orca_output = size_orca_output/1024\n",
    "print(f'Size of ORCA file is: {size_orca_output} KB\\n')\n",
    "\n",
    "if n_jobs > 20:\n",
    "    print(f'Careful, you are working with a possibly large output file of several GB\\n')\n",
    "    print(f'If using version controls consider setting up a .gitignore \\n')\n",
    "\n",
    "if size_orca_output > 1000:\n",
    "    print(f\"Careful, you are working with a '{size_orca_output}' KB large file..\\n\")\n",
    "    print(f'Set up a .gitignore or Git LFS before pushing to Git\\n')\n",
    "\n",
    "# Extract level of theory\n",
    "lot_out = OrcaAnalysis().extract_level_of_theory(orca_output)\n",
    "print(f'Level of theory for the NMR calculations is: {lot_out}\\n')\n",
    "\n",
    "# Split orca output in several subfiles for ease of handling (takes a while)\n",
    "if n_jobs > 2:\n",
    "    print('Your output file will be now spilt into subfiles. \\n')\n",
    "    OrcaAnalysis().split_orca_output(scratch_dir, orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the empirical boundaries ([A]) for various noncovalent interactions\n",
    "OrcaAnalysis().run_boundary_checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize displacement steps in Angstrom - need to find a clever way to do this\n",
    "displacement_steps_distance = [job * 0.25 for job in range(1,n_jobs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_orders = OrcaAnalysis().extract_bond_orders(filename)\n",
    "\n",
    "# Print the bond orders and their interacting nuclei\n",
    "for nucleus, bonds in bond_orders.items():\n",
    "    print(f\"{nucleus}:\")\n",
    "    for interacting_nucleus, bond_order in bonds:\n",
    "        print(f\"  Bond with {interacting_nucleus}: {bond_order}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Extract the CSA tensor components for each nucleus at each distance iteration --- #\n",
    "\n",
    "# Initialize variables for shielding tensor components\n",
    "S_dia = []\n",
    "S_para = []\n",
    "S_tot = []\n",
    "nuclear_identities = []\n",
    "\n",
    "# Extract NMR data from each splitted file\n",
    "for job_number in range (1, n_jobs+1): # split files = number of jobs\n",
    "        \n",
    "    blockPrint()\n",
    "    # Path to the splitted outputs from the .out MPI8 file\n",
    "    orca_splitted_output = OrcaAnalysis().convert_path(os.path.join(scratch_dir, 'OrcaAnalysis/split_orca_output', f'splitted_orca_job{job_number}.out'))\n",
    "    \n",
    "    # Extract CSA data\n",
    "    shielding_dia, shielding_para, shielding_tot, nucleus_info = OrcaAnalysis().extract_tensor_data(orca_splitted_output)\n",
    "\n",
    "    enablePrint()\n",
    "    \n",
    "    # Append shielding tensor matrices (non-diagonalized) - all nuclei for each job iteration\n",
    "    S_dia.append(shielding_dia)\n",
    "    S_para.append(shielding_para)\n",
    "    S_tot.append(shielding_tot)\n",
    "    nuclear_identities.append(nucleus_info)\n",
    "\n",
    "# Transform into PAS \n",
    "# Iterate over each job's shielding tensors in S_tot\n",
    "for job_index, shielding_dict in enumerate(S_tot):\n",
    "    \n",
    "    rows = []\n",
    "    columns = ('Nucleus', '\\u03C3_iso', '\\u03C3_11', '\\u03C3_22', '\\u03C3_33', 'Symmetry')\n",
    "   \n",
    "    # Check if shielding_dict is a dictionary and contains items\n",
    "    if isinstance(shielding_dict, dict):\n",
    "\n",
    "        for nucleus_key, tensor in shielding_dict.items():\n",
    "            \n",
    "            shielding_tensor, s_iso, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(tensor)\n",
    "            \n",
    "            sigma_11 = diagonal_mehring[0][0]\n",
    "            sigma_22 = diagonal_mehring[1][1]\n",
    "            sigma_33 = diagonal_mehring[2][2]\n",
    "            data = (nucleus_key, s_iso, sigma_11, sigma_22, sigma_33, symmetry)\n",
    "            \n",
    "            # Collect the row data in a list\n",
    "            rows.append(data)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Expected a dictionary but got {type(shielding_dict)}\")\n",
    "\n",
    "    # Convert rows to a DataFrame and concatenate\n",
    "    df = pd.concat([pd.DataFrame([row], columns=columns) for row in rows], ignore_index=True)\n",
    "    \n",
    "        \n",
    "    df_out = os.path.join(scratch_dir, f'OrcaAnalysis/dataframe_job{job_index}.csv'\n",
    "    df.to_csv(df_out, index=False)\n",
    "    print(f\"Saved {df_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data from dataframes\n",
    "\n",
    "csv_files = glob.glob('dataframe_job*.csv')  # Adjust the pattern if necessary\n",
    "\n",
    "for job_index, file in enumerate(csv_files):\n",
    "    \n",
    "    df = pd.read_csv(file, header=None, names=['Nucleus', 's_iso', 'σ_11', 'σ_22', 'σ_33', 'Symmetry'])\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        nucleus = row['Nucleus'].strip()\n",
    "        s_iso = row['s_iso']\n",
    "        sigma_11 = row['σ_11']\n",
    "        sigma_22 = row['σ_22']\n",
    "        sigma_33 = row['σ_33']\n",
    "\n",
    "        if nucleus not in nucleus_data:\n",
    "            nucleus_data[nucleus] = []\n",
    "        \n",
    "        # Append the s_iso value for this job_index\n",
    "        nucleus_data[nucleus].append(s_iso)\n",
    "        \n",
    "for nucleus, s_iso_values in nucleus_data.items():\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(s_iso_values)), s_iso_values, marker='o')\n",
    "    plt.title(f's_iso values for {nucleus}')\n",
    "    plt.xlabel('Job Index')\n",
    "    plt.ylabel('s_iso')\n",
    "\n",
    "    plt.show() \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecule = 'D:/PhD/Data/DFT/NONCOV/DFT_simulations/codes/scratch/test_structs/benzene_H2O.xyz'\n",
    "molecule = 'C:/Users/ettor/Desktop/NONCOV/scratch/test_structs/benzene_H2O.xyz'\n",
    "\n",
    "MolView().plot_3d_molecule(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot euler angles and rotated tensor\n",
    "tensor_pas = np.diag([1.0, 2.0, 3.0])  # Diagonal tensor in PAS\n",
    "alpha, beta, gamma = 30, 45, 60  # Euler angles in degrees\n",
    "MolView.plot_3D_tensors_and_axes(tensor_pas, alpha, beta, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: NMRFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to Euler angles\n",
    "mode = 'AZYZ'\n",
    "order = 'Ascending'\n",
    "alpha, beta, gamma, tensor_pas = NMRFunctions().tensor_to_euler(shielding_tensor, eigenvals, eigenvecs, symmetry, mode, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate equivalent sets of angles\n",
    "NMRFunctions().EqEulerSet(alpha,beta,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolecularGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment1 =(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n",
    "fragment2 = (13, 14, 15)\n",
    "\n",
    "mol_graph = MolecularGraph()\n",
    "\n",
    "# Parse the XYZ file\n",
    "atom_types, coordinates = mol_graph.parse_xyz(mol_dir)\n",
    "\n",
    "# Calculate pairwise distances\n",
    "distances = mol_graph.calculate_distances(coordinates)\n",
    "\n",
    "# Detect covalent bonds\n",
    "covalent_bonds = mol_graph.detect_bonds(atom_types, distances)\n",
    "\n",
    "# Detect non-covalent interactions\n",
    "noncovalent_interactions = mol_graph.detect_noncovalent_interactions(atom_types, distances)\n",
    "\n",
    "# Build the molecular graph\n",
    "#mol_graph = mol_graph.build_molecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "\n",
    "# Visualize the molecular graph\n",
    "#mol_graph.draw()\n",
    "\n",
    "# Plots \n",
    "mol_graph.plot_bond_dist_matrix(covalent_bonds, distances, atom_types)\n",
    "mol_graph.plot_noncov_distance_map(noncovalent_interactions, atom_types)\n",
    "\n",
    "# Build different graphs\n",
    "covalent_bonds_graph = mol_graph.build_covalent_bonds_graph(atom_types, coordinates, covalent_bonds)\n",
    "intramolecular_graph = mol_graph.build_intramolecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "intermolecular_graph = mol_graph.build_intermolecular_graph(atom_types, coordinates, noncovalent_interactions)\n",
    "\n",
    "# Draw subplots while preserving atom positions\n",
    "mol_graph.draw_subplots(covalent_bonds_graph, intramolecular_graph, intermolecular_graph, coordinates)\n",
    "\n",
    "\n",
    "threshold = 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: DistanceScanner & RotationScanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH RELATIVE PATHS \n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# LOGS AND ERRORS\n",
    "error_log_file = 'error_log_file.txt' # to finish\n",
    "log_file = 'log_file.txt' # to finish\n",
    "\n",
    "\n",
    "# START TIMER: COMPUTE EFFECTIVE WALL TIME\n",
    "start = timer() # this is not in [sec] i think\n",
    "\n",
    "# SECTON: MAIN\n",
    "def main():\n",
    "\n",
    "    # Relative paths\n",
    "    start_structure = os.path.join(current_dir, 'input_structures/KLaL_cation_pi_RCCE_opt_NICS.xyz')\n",
    "    centroid_out = os.path.join(current_dir, 'centroid_output/centroid_file.xyz')\n",
    "    input_file = os.path.join(current_dir, 'input_file/input_file.txt')\n",
    "\n",
    "    # Read xyz file: this should be either a fully optimized geometry or one with relaxed H\n",
    "    coordinates, atom_identities = read_atomic_coord(start_structure)\n",
    "    print(f'Starting coordinates: {coordinates}')\n",
    "    print(f'Atom identities: {atom_identities}')\n",
    "\n",
    "    # Assign coordinates to molecular fragments, check nomenclature of your atoms in avogadro or any other molecular graphics soft\n",
    "    coords1, coords2 = assign_molecule_fragments(coordinates, input_file)\n",
    "\n",
    "    # Concatenate coordinates for k-means clustering\n",
    "    all_coords = np.concatenate((coords1, coords2), axis=0)\n",
    "    # print(f'All coords: {all_coords}')\n",
    "\n",
    "    # Count how many fragments you have defined in the input file, important for accurate K-means clustering\n",
    "    n_fragments = count_fragments(input_file)\n",
    "    print(f\"Number of '$fragment' occurrences: {n_fragments}\")\n",
    "\n",
    "    # Perform k-means clustering to compute centroids\n",
    "    kmeans = KMeans(n_clusters=n_fragments) # K-means clusters = number of centroids = number of fragments\n",
    "    kmeans.fit(all_coords)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Compute centroids for each fragment\n",
    "    fragment_centroids = calculate_centroids([coords1, coords2])\n",
    "\n",
    "    # Write centroid coordinates to file\n",
    "    write_centroids(centroid_out, fragment_centroids)\n",
    "    print(f'Centroid coordinates: {fragment_centroids}')\n",
    "\n",
    "    # Calculate displacement direction (line connecting centroids)\n",
    "    displacement_direction = centroids[1] - centroids[0]\n",
    "    displacement_direction /= np.linalg.norm(displacement_direction)\n",
    "    print(f'Displacement direction:{displacement_direction}')\n",
    "\n",
    "    # Read displacement step size from input file\n",
    "    displacement_step = None\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        read_displacement = False\n",
    "        for line in lines:\n",
    "            if read_displacement:\n",
    "                displacement_values = line.strip().split()\n",
    "                if displacement_values:\n",
    "                    displacement_step = float(displacement_values[0])\n",
    "                    break\n",
    "            elif line.strip() == \"$displacement\":\n",
    "                read_displacement = True\n",
    "\n",
    "    if displacement_step is None:\n",
    "        print('ERROR: displacement step size not found in input file, please specify it! Syntax => $displacement + number')\n",
    "        return\n",
    "    print(f'Displacement step is: {displacement_step}') # please doublecheck that it is the same value you defined in the input\n",
    "\n",
    "    # Displace the first fragment iteratively and save each structure\n",
    "    displaced_fragment_coords = coords1.copy()  # Make a copy of the original coordinates of the fragment that is displaced\n",
    "    print(f'Original coordinates displaced fragment:', displaced_fragment_coords)\n",
    "\n",
    "    # Initialize the coordinates for the fixed fragment (e.g., coords2)\n",
    "    coords_fixed = coords2.copy() # make a copy of the fixed fragment coordinates to append to the displaced ones\n",
    "    print(f'Original coordinates fixed fragment:', coords_fixed)\n",
    "\n",
    "    all_displaced_fragment_coords = [displaced_fragment_coords]  # List to store all displaced structures\n",
    "\n",
    "    # Combine displaced coordinates with original ones\n",
    "    all_combined_coords = [np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)]  # List to store all combined structures\n",
    "\n",
    "    fragment_centroids = [fragment_centroids[0]]  # List to store all centroids\n",
    "\n",
    "    # Dissociation limit NEED AT LEAST 40 OF THEM MINIMUM\n",
    "    diss_lim = 50 # change with the output value in agnstrom from func(dissociation_limit)\n",
    "\n",
    "    for i in range(1, diss_lim):  # Iterate 50 times (adjust the number as needed) put this as to be the dissociation limit of each DFT run\n",
    "        \n",
    "        displacement_vector = [] \n",
    "\n",
    "        # Compute new set of coordinates for displaced fragments, change $displacement value in input file to tune the displacement\n",
    "        displaced_fragment_coords = displace_fragment(coords1, displacement_direction, displacement_step, i)\n",
    "        #print(f'Displaced fragment coord is: {displaced_fragment_coords}')\n",
    "\n",
    "        combined_coords = np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)\n",
    "        all_combined_coords.append(combined_coords)\n",
    "\n",
    "        # Update centroids for the displaced structure\n",
    "        fragment_centroid = calculate_centroids([displaced_fragment_coords])\n",
    "        fragment_centroids.append(fragment_centroid[0])\n",
    "        print(f'Updated centroids:', fragment_centroid)\n",
    "\n",
    "        # Write displaced structure to file\n",
    "        output_file = Path(os.path.join(current_dir, f'displaced_structures/displaced_structure_{i}.xyz'))\n",
    "        write_displaced_xyz_file(output_file, coords_fixed, displaced_fragment_coords, atom_identities)\n",
    "\n",
    "        all_displaced_fragment_coords.append(displaced_fragment_coords)\n",
    "\n",
    "        # Compute distance between the fixed fragment centroid and all the atoms from the displaced fragment\n",
    "        centroid_to_displaced_distance = compute_distance_from_centroid(displaced_fragment_coords, centroids)\n",
    "        print(f'Distance between displaced coordinates and centroid is: {centroid_to_displaced_distance}')\n",
    "\n",
    "        # Write distances to file - needed for DFT calculations outputs\n",
    "        distance_output_file = Path(os.path.join(current_dir, f'distance_files/distances_structures_{i}.xyz'))\n",
    "        write_distances_file(distance_output_file, displaced_fragment_coords, centroid_to_displaced_distance, atom_identities, displacement_step)\n",
    "\n",
    "\n",
    "    # Plot initial topology for molecular fragments and centroids\n",
    "    fig = plot_starting_molecular_fragments(coords1, coords2, centroids)\n",
    "\n",
    "    # Generate colors for the plots based on displacement iteration\n",
    "    num_iterations = len(all_displaced_fragment_coords)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 1.0, num_iterations))\n",
    "\n",
    "    # Plot displaced molecular fragments and centroids\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot original fragments and centroids\n",
    "    ax.scatter(coords1[:, 0], coords1[:, 1], coords1[:, 2], color=colors[0], label='Molecule 1 (Original)')\n",
    "    ax.scatter(coords2[:, 0], coords2[:, 1], coords2[:, 2], color=colors[0], label='Molecule 2 (Original)')\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], color=colors[0], marker='x', s=100, label='Centroids (Original)')\n",
    "\n",
    "    # Plot displaced fragments and centroids\n",
    "    for i, displaced_coords in enumerate(all_displaced_fragment_coords[1:], start=1):\n",
    "        color = colors[i]\n",
    "        label = f'Iteration {i}'\n",
    "        ax.scatter(displaced_coords[:, 0], displaced_coords[:, 1], displaced_coords[:, 2], color=color, label=label)\n",
    "        ax.scatter(fragment_centroids[i][0], fragment_centroids[i][1], fragment_centroids[i][2], color=color, marker='x', s=100, label=f'Centroids ({label})')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # END TIMER: STOP TIMER AND PRINT\n",
    "    elapsed_time = timer() - start  # in seconds\n",
    "    print(f'Elapsed time for the code to run is: {elapsed_time}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: AminoStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# toolbox = NONCOVToolbox()\n",
    "# amino_stats = toolbox.AminoStat()\n",
    "\n",
    "# # Example usage\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# protein_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spidersilks.txt')\n",
    "# spaced_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spaced_spidersilks.txt')\n",
    "# count_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_count.txt')\n",
    "# plot_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_statistics.pdf')\n",
    "\n",
    "# #amino_stats = AminoStat()\n",
    "\n",
    "# amino_stats.space_prot_seq(protein_sequence, spaced_sequence)\n",
    "# amino_stats.count_amino_acids(spaced_sequence, count_file)\n",
    "# amino_stats.plot_amino_acid_statistics(count_file, plot_file)\n",
    "\n",
    "# amino_stats.define_protein_domains()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here xtb, CENSO, CREST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
