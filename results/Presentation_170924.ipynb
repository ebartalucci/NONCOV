{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noncovalent interactions and NMR observables\n",
    "## NONCOV Toolbox in Python\n",
    "\n",
    "### Ettore Bartalucci, Progress Report 17.09.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfig NONCOVToolbox Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NONCOVToolbox library and print header\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_noncov = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "if path_noncov not in sys.path:\n",
    "    sys.path.append(path_noncov)\n",
    "\n",
    "from noncov import NONCOVToolbox, NONCOVHeader\n",
    "\n",
    "noncov = NONCOVToolbox()\n",
    "\n",
    "#NONCOVHeader.print_header()\n",
    "\n",
    "# OrcaAnalysis module for postprocessing of DFT calculations\n",
    "from noncov import OrcaAnalysis\n",
    "\n",
    "# Show performance and features of various NMR functions in module\n",
    "from noncov import NMRFunctions\n",
    "\n",
    "# Display the molecule while its displaced, not yet interactive in Jupyter but interactive in VS Code\n",
    "from noncov import MolView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration file \n",
    "configdir = os.getcwd()\n",
    "configdir = os.path.abspath(os.path.join('..', 'config'))\n",
    "\n",
    "configs = os.path.join(configdir, 'configuration.yml')\n",
    "print(f'Change with care, configuration file is in:', configs)\n",
    "\n",
    "print('And looks like this...\\n')\n",
    "with open(configs,'r') as f:\n",
    "    config_file = f.read()\n",
    "    print(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory is: d:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\results\n",
      "Current scratch directory is: d:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\scratch\n",
      "Current molecule directory is: d:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\scratch\\test_structs/benzene_H2O.xyz\n"
     ]
    }
   ],
   "source": [
    "# Get work directory and scratch folder for the output data\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current work directory is: {current_dir}')\n",
    "\n",
    "scratch_dir = os.path.abspath(os.path.join('..', 'scratch'))\n",
    "print(f'Current scratch directory is: {scratch_dir}')\n",
    "\n",
    "mol_dir = os.path.join(scratch_dir, 'test_structs/benzene_H2O.xyz')\n",
    "print(f'Current molecule directory is: {mol_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: OrcaAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Provide files you want to process as input \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Example: \"D:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\tests\\data\\KLaL_cation_pi_RCCE_opt.mpi8.out\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m orca_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the path to the ORCA file you want to work with: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m orca_output \u001b[38;5;241m=\u001b[39m OrcaAnalysis()\u001b[38;5;241m.\u001b[39mconvert_path(orca_output)\n\u001b[0;32m      5\u001b[0m scratch_dir \u001b[38;5;241m=\u001b[39m OrcaAnalysis()\u001b[38;5;241m.\u001b[39mconvert_path(scratch_dir)\n",
      "File \u001b[1;32mc:\\Users\\Ettore Bartalucci\\.virtualenvs\\Ettore_Bartalucci-IfGXvshO\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ettore Bartalucci\\.virtualenvs\\Ettore_Bartalucci-IfGXvshO\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Provide files you want to process as input \n",
    "# Example: \"D:\\PhD\\Data\\DFT\\NONCOV\\DFT_simulations\\codes\\tests\\data\\KLaL_cation_pi_RCCE_opt.mpi8.out\"\n",
    "orca_output = input(\"Enter the path to the ORCA file you want to work with: \")\n",
    "orca_output = OrcaAnalysis().convert_path(orca_output)\n",
    "scratch_dir = OrcaAnalysis().convert_path(scratch_dir)\n",
    "mol_dir = OrcaAnalysis().convert_path(mol_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with ORCA .out files\n",
    "\n",
    "# Count how many sequential calculations have been done\n",
    "n_jobs = OrcaAnalysis().count_jobs_number(orca_output)\n",
    "print(f'Number of ORCA jobs in file: {n_jobs}\\n')\n",
    "\n",
    "# Compute size of the .out file and suggest Git LFS \n",
    "size_orca_output = os.path.getsize(orca_output)\n",
    "size_orca_output = size_orca_output/1024\n",
    "print(f'Size of ORCA file is: {size_orca_output} KB\\n')\n",
    "\n",
    "if n_jobs > 20:\n",
    "    print(f'Careful, you are working with a possibly large output file of several GB\\n')\n",
    "    print(f'If using version controls consider setting up a .gitignore \\n')\n",
    "\n",
    "if size_orca_output > 1000:\n",
    "    print(f\"Careful, you are working with a '{size_orca_output}' KB large file..\\n\")\n",
    "    print(f'Set up a .gitignore or Git LFS before pushing to Git\\n')\n",
    "\n",
    "# Extract level of theory\n",
    "lot_out = OrcaAnalysis().extract_level_of_theory(orca_output)\n",
    "print(f'Level of theory for the NMR calculations is: {lot_out}\\n')\n",
    "\n",
    "# Split orca output in several subfiles for ease of handling (takes a while)\n",
    "if n_jobs > 2:\n",
    "    print('Your output file will be now spilt into subfiles. \\n')\n",
    "    #OrcaAnalysis().split_orca_output(scratch_dir, orca_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the empirical boundaries ([A]) for various noncovalent interactions\n",
    "OrcaAnalysis().run_boundary_checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize displacement steps in Angstrom - need to find a clever way to do this\n",
    "displacement_steps_distance = [job * 0.25 for job in range(1,n_jobs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable printing\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore printing\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Extract the CSA tensor components for each nucleus at each distance iteration --- #\n",
    "\n",
    "# Initialize variables for shielding tensor components\n",
    "S_dia = []\n",
    "S_para = []\n",
    "S_tot = []\n",
    "nuclear_identities = []\n",
    "\n",
    "# Extract NMR data from each splitted file\n",
    "for job_number in range (1, n_jobs+1): # split files = number of jobs\n",
    "        \n",
    "    # Path to the splitted outputs from the .out MPI8 file\n",
    "    orca_splitted_output = OrcaAnalysis().convert_path(os.path.join(scratch_dir, 'OrcaAnalysis/split_orca_output', f'splitted_orca_job{job_number}.out'))\n",
    "    \n",
    "    # Extract CSA data\n",
    "    shielding_dia, shielding_para, shielding_tot, nucleus_info = OrcaAnalysis().extract_csa_data(orca_splitted_output)\n",
    "    \n",
    "    # Append shielding tensor matrices (non-diagonalized) - all nuclei for each job iteration\n",
    "    S_dia.append(shielding_dia)\n",
    "    S_para.append(shielding_para)\n",
    "    S_tot.append(shielding_tot)\n",
    "    nuclear_identities.append(nucleus_info)\n",
    "\n",
    "# Transform into PAS \n",
    "original_shielding_tensors = []\n",
    "s_iso_all = []\n",
    "diagonal_mehring_all = []\n",
    "diagonal_haberlen_all = []\n",
    "eigenvals_all = []\n",
    "eigenvecs_all = []\n",
    "symmetry_all = []\n",
    "\n",
    "# Iterate over each job's shielding tensors in S_tot\n",
    "for job_index, shielding_dict in enumerate(S_tot):\n",
    "    \n",
    "    # Check if shielding_dict is a dictionary and contains items\n",
    "    if isinstance(shielding_dict, dict):\n",
    "        for nucleus_key, tensor in shielding_dict.items():\n",
    "            \n",
    "            # Diagonalize the tensor\n",
    "            shielding_tensor, s_iso, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(tensor)\n",
    "            \n",
    "            # Append the results to the lists\n",
    "            original_shielding_tensors.append((nucleus_key, shielding_tensor, job_index))\n",
    "            s_iso_all.append((nucleus_key, s_iso, job_index))\n",
    "            diagonal_mehring_all.append((nucleus_key, diagonal_mehring, job_index))\n",
    "            diagonal_haberlen_all.append((nucleus_key, diagonal_haberlen, job_index))\n",
    "            eigenvals_all.append((nucleus_key, eigenvals, job_index))\n",
    "            eigenvecs_all.append((nucleus_key, eigenvecs, job_index))\n",
    "            symmetry_all.append((nucleus_key, symmetry, job_index))\n",
    "    else:\n",
    "        print(f\"Error: Expected a dictionary but got {type(shielding_dict)}\")\n",
    "\n",
    "# Do the same for diamagnetic and paramagnetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tensor_shielding(nuclear_identities, s_iso_all, diagonal_mehring_all, displacement_steps_distance, scratch_dir, n_jobs):\n",
    "\n",
    "    tensor_plots = os.path.join(scratch_dir, 'OrcaAnalysis/test_tensor_plots')\n",
    "    tensor_plots = OrcaAnalysis().convert_path(tensor_plots)\n",
    "    os.makedirs(tensor_plots, exist_ok=True)\n",
    "\n",
    "    for job_number in range (1, n_jobs+1): # split files = number of jobs\n",
    "        \n",
    "        s_iso = []\n",
    "        s_11 = []\n",
    "        s_22 = []\n",
    "        s_33 = []\n",
    "\n",
    "        for i, nucleus in enumerate(nuclear_identities):\n",
    "\n",
    "            sigma_iso = s_iso_all[i]\n",
    "            sigma_iso = sigma_iso[1]\n",
    "\n",
    "            diag_tensor = diagonal_mehring_all[i]\n",
    "            diag_tensor = diag_tensor[1]\n",
    "            sigma_11 = diag_tensor[0]  \n",
    "            sigma_22 = diag_tensor[1]  \n",
    "            sigma_33 = diag_tensor[2] \n",
    "            \n",
    "            sigma_11 = sigma_11[0]  \n",
    "            sigma_22 = sigma_22[1]  \n",
    "            sigma_33 = sigma_33[2] \n",
    "\n",
    "            s_iso.append(sigma_iso)\n",
    "            s_11.append(sigma_11)\n",
    "            s_22.append(sigma_22)\n",
    "            s_33.append(sigma_iso)\n",
    "\n",
    "        # Plot the isotropic shift and the diagonal tensor components\n",
    "        plt.plot(displacement_steps_distance[job_number], s_iso[job_number], marker='o', linestyle='-', color='blue', label=r'$\\sigma$_iso')\n",
    "        plt.plot(displacement_steps_distance, s_11, marker='o', linestyle='-', color='red', label=r'$\\sigma$_11')\n",
    "        plt.plot(displacement_steps_distance, s_22, marker='o', linestyle='-', color='magenta', label=r'$\\sigma$_22')\n",
    "        plt.plot(displacement_steps_distance, s_33, marker='o', linestyle='-', color='gold', label=r'$\\sigma$_33')\n",
    "\n",
    "        # Highlight the NONCOV effective region (optional, can be commented out if not needed)\n",
    "        #if min_distance_value is not None and max_distance_value is not None:\n",
    "        #    plt.axvspan(min_distance_value, max_distance_value, alpha=0.2, color='grey', label='NONCOV \\n effective region')\n",
    "\n",
    "        # Set labels and title\n",
    "        plt.xlabel('Displacement')\n",
    "        plt.ylabel('Shielding / ppm')\n",
    "        plt.title(f'Nucleus {nucleus[i]}')\n",
    "        pdf_filename = os.path.join(tensor_plots, f'{nucleus[i]}.pdf')\n",
    "        jpg_filename = os.path.join(tensor_plots, f'{nucleus[i]}.jpg')\n",
    "\n",
    "\n",
    "    # Display legend\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Save the plot as a PDF in the output folder\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "\n",
    "    # Save the plot as a JPEG in the output folder\n",
    "    plt.savefig(jpg_filename, bbox_inches='tight')        \n",
    "\n",
    "    # Clear the current figure for the next iteration\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_tensor_shielding(nuclear_identities, s_iso_all, diagonal_mehring_all, displacement_steps_distance, scratch_dir, n_jobs):\n",
    "    \n",
    "    tensor_plots = os.path.join(scratch_dir, 'OrcaAnalysis/test_tensor_plots')\n",
    "    tensor_plots = OrcaAnalysis().convert_path(tensor_plots)\n",
    "    os.makedirs(tensor_plots, exist_ok=True)\n",
    "\n",
    "    if isinstance(nuclear_identities[0], list):\n",
    "        nuclear_identities = [tuple(nuc) for nuc in nuclear_identities]\n",
    "\n",
    "    nucleus_data = {nucleus: {'displacements': [], 's_iso': []} for nucleus in nuclear_identities}\n",
    "\n",
    "    for i, nucleus in enumerate(nuclear_identities):\n",
    "        sigma_iso = s_iso_all[i]\n",
    "        sigma_iso = sigma_iso[1]  \n",
    "\n",
    "        for job_number in range(1, n_jobs + 1):\n",
    "            \n",
    "            displacements = displacement_steps_distance[job_number - 1]  # Correct zero-based indexing\n",
    "            nucleus_data[nucleus]['displacements'].append(displacements)\n",
    "\n",
    "            s_iso = sigma_iso\n",
    "            nucleus_data[nucleus]['s_iso'].append(s_iso)\n",
    "\n",
    "    for nucleus, data in nucleus_data.items():\n",
    "\n",
    "        for i in range(1,len(nucleus)):\n",
    "\n",
    "            plt.figure()\n",
    "            \n",
    "            # Plot the progression of s_iso as a function of displacement steps\n",
    "            plt.plot(data['displacements'], data['s_iso'], marker='o', linestyle='-', label=f'Nucleus {i}')\n",
    "                    \n",
    "            nucleus_name = nucleus.replace(' ', '_').replace(':', '')\n",
    "\n",
    "            plt.xlabel('Displacement Steps Distance')\n",
    "            plt.ylabel(r'$\\sigma_\\text{iso}$')\n",
    "            plt.title(f'Isotropic Shielding Progression for Nucleus: {nucleus_name}')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Save the plot for the current nucleus\n",
    "            plot_file = os.path.join(tensor_plots, f'{nucleus_name}_isotropic_shielding.png')\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.simplefilter(\"ignore\", np.ComplexWarning)\n",
    "\n",
    "plot_tensor_shielding(nuclear_identities, s_iso_all, diagonal_mehring_all, \n",
    "                          displacement_steps_distance, scratch_dir, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecule = 'D:/PhD/Data/DFT/NONCOV/DFT_simulations/codes/scratch/test_structs/benzene_H2O.xyz'\n",
    "molecule = 'C:/Users/ettor/Desktop/NONCOV/scratch/test_structs/benzene_H2O.xyz'\n",
    "\n",
    "MolView().plot_3d_molecule(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot euler angles and rotated tensor\n",
    "tensor_pas = np.diag([1.0, 2.0, 3.0])  # Diagonal tensor in PAS\n",
    "alpha, beta, gamma = 30, 45, 60  # Euler angles in degrees\n",
    "MolView().plot_3D_tensors_and_axes(tensor_pas, alpha, beta, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: NMRFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-5.9766, -65.5206, -9.5073], [-60.302, -23.0881, -28.2399], [-10.8928, -25.2372, 56.277])\n",
      "# -------------------------------------------------- #\n",
      "# TENSOR DIAGONALIZATION FUNCTION HAS BEEN REQUESTED #\n",
      "\n",
      "\n",
      "Shielding Tensor is: \n",
      "[[ -5.9766 -65.5206  -9.5073]\n",
      " [-60.302  -23.0881 -28.2399]\n",
      " [-10.8928 -25.2372  56.277 ]]\n",
      "Proceeding to transposing...\n",
      "\n",
      "Transposed matrix is: \n",
      "[[ -5.9766 -60.302  -10.8928]\n",
      " [-65.5206 -23.0881 -25.2372]\n",
      " [ -9.5073 -28.2399  56.277 ]]\n",
      "Proceeding to symmetrization...\n",
      "\n",
      "Symmetric tensor is: \n",
      "[[ -5.9766  -62.9113  -10.20005]\n",
      " [-62.9113  -23.0881  -26.73855]\n",
      " [-10.20005 -26.73855  56.277  ]]\n",
      "\n",
      "Antisymmetric tensor is. \n",
      "[[ 0.      -2.6093   0.69275]\n",
      " [ 2.6093   0.      -1.50135]\n",
      " [-0.69275  1.50135  0.     ]]\n",
      "\n",
      "Since antisymmetric part does not contribute to observable, skipping...\n",
      "\n",
      "Proceeding to diagonalization...\n",
      "\n",
      "Eigenvalues are: [-83.17  43.79  66.59], Eigenvectors are: \n",
      "[[ 0.65  0.76  0.32]\n",
      " [ 0.74 -0.52 -0.47]\n",
      " [ 0.18 -0.39  0.82]]\n",
      "\n",
      "Proceeding to ordering eigenvalues and eigenvectors...\n",
      "\n",
      "Magnitude-based ordering of eigenvalues is: \n",
      "[ 43.79  66.59 -83.17] \n",
      " and of eigenvectors is: \n",
      "[[ 0.76  0.32  0.65]\n",
      " [-0.52 -0.47  0.74]\n",
      " [-0.39  0.82  0.18]].\n",
      "Proceeding to diagonalization...\n",
      "\n",
      "Diagonalized tensor is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "Proceeding to compute isotropic shift...\n",
      "\n",
      "Isotropic shift is: 9.07 ppm\n",
      "Proceeding to Haberlen ordering...\n",
      "\n",
      "Diagonal tensor in Haberlen order is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "\n",
      "where:\n",
      " σ_XX:-83.17 \n",
      " σ_YY:43.79 \n",
      " σ_ZZ:66.59\n",
      "Proceeding to Mehring ordering...\n",
      "\n",
      "Diagonal tensor in Mehring order is: \n",
      "[[-83.17   0.     0.  ]\n",
      " [  0.    43.79   0.  ]\n",
      " [  0.     0.    66.59]]\n",
      "\n",
      "where:\n",
      " σ_11:-83.17 \n",
      " σ_22:43.79 \n",
      " σ_33:66.59 \n",
      "\n",
      "Proceeding to shielding tensor symmetry analysis...\n",
      "\n",
      "Symmetry of the tensor based on eigenvals count is: 0\n",
      "\n",
      "which means that the tensor is completely anysotropic \n",
      "\n",
      "The tensor is not symmetric (S != S^T).\n",
      "\n",
      "Checking for rotational symmetry:\n",
      "\n",
      "Eigenvector row 1: [0.65 0.74 0.18]\n",
      "Eigenvector row 2: [ 0.76 -0.52 -0.39]\n",
      "Eigenvector row 3: [ 0.32 -0.47  0.82]\n",
      "180 degrees rotation results in the tensor: \n",
      "[[ 56.277  -25.2372 -10.8928]\n",
      " [-28.2399 -23.0881 -60.302 ]\n",
      " [ -9.5073 -65.5206  -5.9766]]\n",
      "\n",
      "Rotational symmetry is: \n",
      "False\n",
      "\n",
      "Proceeding...\n",
      "\n",
      "Call tensor_to_euler for Euler angles extraction from eigenvectors...\n",
      "\n",
      "# -------------------------------------------------- #\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Test random tensor\n",
    "xx =-5.9766\n",
    "xy =-65.5206\n",
    "xz =-9.5073\n",
    "yx =-60.3020\n",
    "yy =-23.0881\n",
    "yz =-28.2399\n",
    "zx =-10.8928\n",
    "zy =-25.2372\n",
    "zz =56.277\n",
    "\n",
    "tensor = [xx, xy, xz], [yx, yy, yz], [zx, zy, zz]\n",
    "print(tensor)\n",
    "\n",
    "# Diagonalize tensor\n",
    "shielding_tensor, s_iso, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(tensor)\n",
    "\n",
    "sigma_11 = diagonal_mehring[0][0]\n",
    "sigma_22 = diagonal_mehring[1][1]\n",
    "sigma_33 = diagonal_mehring[2][2]\n",
    "\n",
    "nuclei = []\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "e = []\n",
    "\n",
    "for i in range (1,7):\n",
    "    nucleus = i+1\n",
    "    y = s_iso\n",
    "    z = sigma_11\n",
    "    j = sigma_22\n",
    "    k = sigma_33\n",
    "    l = symmetry\n",
    "\n",
    "    nuclei.append(nucleus)\n",
    "    a.append(y)\n",
    "    b.append(z)\n",
    "    c.append(j)\n",
    "    d.append(k)\n",
    "    e.append(l)\n",
    "\n",
    "data = (nuclei,a,b,c,d,e)\n",
    "\n",
    "columns = ('Nucleus', 's_iso', 'sigma_11', 'sigma_22', 'sigma_33', 'symmetry')\n",
    "\n",
    "df = pd.DataFrame(data=data, index=columns).T\n",
    "df \n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        Nucleus   sdia  spara stot\n",
       " 0  Nucleus 3H :  27.48  23.16    0,\n",
       "         Nucleus        sdia       spara stot\n",
       " 0  Nucleus 4H :  (26.93+0j)  (23.25+0j)    0,\n",
       "         Nucleus   sdia  spara stot\n",
       " 0  Nucleus 7H :  24.21  20.22    0,\n",
       "         Nucleus   sdia  spara stot\n",
       " 0  Nucleus 9H :  24.76  20.51    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 11H :  24.16  20.24    0,\n",
       "          Nucleus       sdia       spara stot\n",
       " 0  Nucleus 14H :  (26.3+0j)  (22.93+0j)    0,\n",
       "          Nucleus  sdia  spara stot\n",
       " 0  Nucleus 15H :  27.7  23.25    0,\n",
       "          Nucleus  sdia  spara stot\n",
       " 0  Nucleus 18H :  23.5  19.86    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 20H :  23.78  20.01    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 22H :  23.78  19.8    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 29H :  27.36  22.97    0,\n",
       "          Nucleus        sdia       spara stot\n",
       " 0  Nucleus 30H :  (27.02+0j)  (23.25+0j)    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 33H :  23.96  20.1    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 35H :  24.56  20.25    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 37H :  24.03  20.19    0,\n",
       "          Nucleus        sdia       spara stot\n",
       " 0  Nucleus 40H :  (27.18+0j)  (23.57+0j)    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 41H :  27.34  22.86    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 44H :  23.64  19.87    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 46H :  23.76  19.97    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 48H :  23.61  19.74    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 53H :  11.14 -5.68    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 55H :  30.52  26.09    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 56H :  29.99  19.53    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 58H :  12.58  -3.6    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 60H :  30.51  26.06    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 61H :  29.96  19.39    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 62H :  26.57  19.98    0,\n",
       "          Nucleus  sdia spara stot\n",
       " 0  Nucleus 63H :  23.4  15.2    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 64H :  27.52  19.65    0,\n",
       "          Nucleus  sdia  spara stot\n",
       " 0  Nucleus 65H :  23.2  14.17    0,\n",
       "         Nucleus    sdia   spara stot\n",
       " 0  Nucleus 2C :  152.03  135.06    0,\n",
       "         Nucleus  sdia  spara stot\n",
       " 0  Nucleus 5C :  48.0 -39.68    0,\n",
       "         Nucleus   sdia  spara stot\n",
       " 0  Nucleus 6C :  42.17 -66.45    0,\n",
       "         Nucleus   sdia  spara stot\n",
       " 0  Nucleus 8C :  55.29 -52.91    0,\n",
       "          Nucleus  sdia  spara stot\n",
       " 0  Nucleus 10C :  40.8 -68.39    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 12C :  47.29 -35.7    0,\n",
       "          Nucleus    sdia  spara stot\n",
       " 0  Nucleus 13C :  152.31  133.9    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 16C :  38.38 -38.08    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 17C :  43.73 -59.46    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 19C :  50.57 -57.43    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 21C :  48.09 -52.54    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 23C :  42.41 -44.24    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 24C :  28.96 -76.38    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 25C :  21.23 -65.98    0,\n",
       "          Nucleus    sdia   spara stot\n",
       " 0  Nucleus 28C :  152.97  135.97    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 31C :  45.71 -39.12    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 32C :  39.99 -68.34    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 34C :  52.01 -56.49    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 36C :  40.76 -66.93    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 38C :  46.47 -39.24    0,\n",
       "          Nucleus    sdia   spara stot\n",
       " 0  Nucleus 39C :  153.78  136.51    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 42C :  40.84 -45.7    0,\n",
       "          Nucleus   sdia spara stot\n",
       " 0  Nucleus 43C :  45.39 -56.8    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 45C :  50.35 -57.57    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 47C :  45.85 -55.42    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 49C :  42.72 -32.84    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 50C :  29.68 -76.31    0,\n",
       "          Nucleus   sdia  spara stot\n",
       " 0  Nucleus 51C :  26.68 -65.86    0,\n",
       "          Nucleus  sdia  spara stot\n",
       " 0  Nucleus 57C :  30.0 -36.44    0,\n",
       "          Nucleus    sdia  spara stot\n",
       " 0  Nucleus 52N :  104.53  44.44    0,\n",
       "          Nucleus    sdia   spara stot\n",
       " 0  Nucleus 54N :  157.71  105.86    0,\n",
       "          Nucleus    sdia   spara stot\n",
       " 0  Nucleus 59N :  157.16  105.17    0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Extract the CSA tensor components for each nucleus at each distance iteration --- #\n",
    "n_jobs = 1\n",
    "\n",
    "# Initialize variables for shielding tensor components\n",
    "S_dia = []\n",
    "S_para = []\n",
    "S_tot = []\n",
    "nuclear_identities = []\n",
    "data = []\n",
    "\n",
    "# Extract NMR data from each splitted file\n",
    "for job_number in range (1, n_jobs+1): # split files = number of jobs\n",
    "        \n",
    "    blockPrint()\n",
    "    # Path to the splitted outputs from the .out MPI8 file\n",
    "    orca_splitted_output = OrcaAnalysis().convert_path(os.path.join(scratch_dir, 'OrcaAnalysis/split_orca_output', f'splitted_orca_job{job_number}.out'))\n",
    "    \n",
    "    # Extract CSA data\n",
    "    shielding_dia, shielding_para, shielding_tot, nucleus_info = OrcaAnalysis().extract_csa_data(orca_splitted_output)\n",
    "\n",
    "    enablePrint()\n",
    "    \n",
    "    # Append shielding tensor matrices (non-diagonalized) - all nuclei for each job iteration\n",
    "    S_dia.append(shielding_dia)\n",
    "    S_para.append(shielding_para)\n",
    "    S_tot.append(shielding_tot)\n",
    "    nuclear_identities.append(nucleus_info)\n",
    "\n",
    "# Transform into PAS \n",
    "original_shielding_tensors = []\n",
    "s_iso_all = []\n",
    "diagonal_mehring_all = []\n",
    "diagonal_haberlen_all = []\n",
    "eigenvals_all = []\n",
    "eigenvecs_all = []\n",
    "symmetry_all = []\n",
    "df = []\n",
    "\n",
    "# Iterate over each job's shielding tensors in S_tot\n",
    "for job_index, shielding_dict in enumerate(S_tot):\n",
    "    \n",
    "    # Check if shielding_dict is a dictionary and contains items\n",
    "    if isinstance(shielding_dict, dict):\n",
    "\n",
    "        for nucleus_key, tensor in shielding_dict.items():\n",
    "            \n",
    "            # Diagonalize the tensor\n",
    "            shielding_tensor, s_iso, diagonal_mehring, diagonal_haberlen, eigenvals, eigenvecs, symmetry = NMRFunctions().diagonalize_tensor(tensor)\n",
    "            \n",
    "            data2 = (nucleus_key, s_iso, diagonal_mehring[0][0], symmetry)\n",
    "            df2 = pd.DataFrame(data=data2, index=columns).T\n",
    "            df.append(df2)\n",
    "\n",
    "            # Append the results to the lists\n",
    "            original_shielding_tensors.append((nucleus_key, shielding_tensor, job_index))\n",
    "            s_iso_all.append((nucleus_key, s_iso, job_index))\n",
    "            diagonal_mehring_all.append((nucleus_key, diagonal_mehring, job_index))\n",
    "            diagonal_haberlen_all.append((nucleus_key, diagonal_haberlen, job_index))\n",
    "            eigenvals_all.append((nucleus_key, eigenvals, job_index))\n",
    "            eigenvecs_all.append((nucleus_key, eigenvecs, job_index))\n",
    "            symmetry_all.append((nucleus_key, symmetry, job_index))\n",
    "    else:\n",
    "        print(f\"Error: Expected a dictionary but got {type(shielding_dict)}\")\n",
    "\n",
    "\n",
    "columns = ('Nucleus', 'sdia', 'spara', 'stot')\n",
    "\n",
    "df \n",
    "\n",
    "#df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to Euler angles\n",
    "mode = 'AZYZ'\n",
    "order = 'Ascending'\n",
    "alpha, beta, gamma, tensor_pas = NMRFunctions().tensor_to_euler(shielding_tensor, eigenvals, eigenvecs, symmetry, mode, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate equivalent sets of angles\n",
    "NMRFunctions().EqEulerSet(alpha,beta,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: MolecularGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(molecule_path):\n",
    "\n",
    "    mol_graph = MolecularGraph()\n",
    "\n",
    "    # Parse the XYZ file\n",
    "    atom_types, coordinates = mol_graph.parse_xyz(molecule_path)\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    distances = mol_graph.calculate_distances(coordinates)\n",
    "    \n",
    "    # Detect covalent bonds\n",
    "    covalent_bonds = mol_graph.detect_bonds(atom_types, distances)\n",
    "    \n",
    "    # Detect non-covalent interactions\n",
    "    noncovalent_interactions = mol_graph.detect_noncovalent_interactions(atom_types, distances)\n",
    "    \n",
    "    # Build the molecular graph\n",
    "    #mol_graph = mol_graph.build_molecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "    \n",
    "    # Visualize the molecular graph\n",
    "    #mol_graph.draw()\n",
    "\n",
    "    # Plots \n",
    "    mol_graph.plot_bond_dist_matrix(covalent_bonds, distances, atom_types)\n",
    "    mol_graph.plot_noncov_distance_map(noncovalent_interactions, atom_types)\n",
    "\n",
    "    # Build different graphs\n",
    "    covalent_bonds_graph = mol_graph.build_covalent_bonds_graph(atom_types, coordinates, covalent_bonds)\n",
    "    intramolecular_graph = mol_graph.build_intramolecular_graph(atom_types, coordinates, covalent_bonds, noncovalent_interactions)\n",
    "    intermolecular_graph = mol_graph.build_intermolecular_graph(atom_types, coordinates, noncovalent_interactions)\n",
    "\n",
    "    # Draw subplots while preserving atom positions\n",
    "    mol_graph.draw_subplots(covalent_bonds_graph, intramolecular_graph, intermolecular_graph, coordinates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold = 1.6\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current working directory is: {current_dir}')\n",
    "#molecule = os.path.join(current_dir, 'scratch/test_structs/caffeine.xyz')\n",
    "\n",
    "molecule = 'D:/PhD/Data/DFT/NONCOV/DFT_simulations/codes/scratch/test_structs/benzene_H2O.xyz'\n",
    "\n",
    "main(molecule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: DistanceScanner & RotationScanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH RELATIVE PATHS \n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# LOGS AND ERRORS\n",
    "error_log_file = 'error_log_file.txt' # to finish\n",
    "log_file = 'log_file.txt' # to finish\n",
    "\n",
    "\n",
    "# START TIMER: COMPUTE EFFECTIVE WALL TIME\n",
    "start = timer() # this is not in [sec] i think\n",
    "\n",
    "# SECTON: MAIN\n",
    "def main():\n",
    "\n",
    "    # Relative paths\n",
    "    start_structure = os.path.join(current_dir, 'input_structures/KLaL_cation_pi_RCCE_opt_NICS.xyz')\n",
    "    centroid_out = os.path.join(current_dir, 'centroid_output/centroid_file.xyz')\n",
    "    input_file = os.path.join(current_dir, 'input_file/input_file.txt')\n",
    "\n",
    "    # Read xyz file: this should be either a fully optimized geometry or one with relaxed H\n",
    "    coordinates, atom_identities = read_atomic_coord(start_structure)\n",
    "    print(f'Starting coordinates: {coordinates}')\n",
    "    print(f'Atom identities: {atom_identities}')\n",
    "\n",
    "    # Assign coordinates to molecular fragments, check nomenclature of your atoms in avogadro or any other molecular graphics soft\n",
    "    coords1, coords2 = assign_molecule_fragments(coordinates, input_file)\n",
    "\n",
    "    # Concatenate coordinates for k-means clustering\n",
    "    all_coords = np.concatenate((coords1, coords2), axis=0)\n",
    "    # print(f'All coords: {all_coords}')\n",
    "\n",
    "    # Count how many fragments you have defined in the input file, important for accurate K-means clustering\n",
    "    n_fragments = count_fragments(input_file)\n",
    "    print(f\"Number of '$fragment' occurrences: {n_fragments}\")\n",
    "\n",
    "    # Perform k-means clustering to compute centroids\n",
    "    kmeans = KMeans(n_clusters=n_fragments) # K-means clusters = number of centroids = number of fragments\n",
    "    kmeans.fit(all_coords)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Compute centroids for each fragment\n",
    "    fragment_centroids = calculate_centroids([coords1, coords2])\n",
    "\n",
    "    # Write centroid coordinates to file\n",
    "    write_centroids(centroid_out, fragment_centroids)\n",
    "    print(f'Centroid coordinates: {fragment_centroids}')\n",
    "\n",
    "    # Calculate displacement direction (line connecting centroids)\n",
    "    displacement_direction = centroids[1] - centroids[0]\n",
    "    displacement_direction /= np.linalg.norm(displacement_direction)\n",
    "    print(f'Displacement direction:{displacement_direction}')\n",
    "\n",
    "    # Read displacement step size from input file\n",
    "    displacement_step = None\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        read_displacement = False\n",
    "        for line in lines:\n",
    "            if read_displacement:\n",
    "                displacement_values = line.strip().split()\n",
    "                if displacement_values:\n",
    "                    displacement_step = float(displacement_values[0])\n",
    "                    break\n",
    "            elif line.strip() == \"$displacement\":\n",
    "                read_displacement = True\n",
    "\n",
    "    if displacement_step is None:\n",
    "        print('ERROR: displacement step size not found in input file, please specify it! Syntax => $displacement + number')\n",
    "        return\n",
    "    print(f'Displacement step is: {displacement_step}') # please doublecheck that it is the same value you defined in the input\n",
    "\n",
    "    # Displace the first fragment iteratively and save each structure\n",
    "    displaced_fragment_coords = coords1.copy()  # Make a copy of the original coordinates of the fragment that is displaced\n",
    "    print(f'Original coordinates displaced fragment:', displaced_fragment_coords)\n",
    "\n",
    "    # Initialize the coordinates for the fixed fragment (e.g., coords2)\n",
    "    coords_fixed = coords2.copy() # make a copy of the fixed fragment coordinates to append to the displaced ones\n",
    "    print(f'Original coordinates fixed fragment:', coords_fixed)\n",
    "\n",
    "    all_displaced_fragment_coords = [displaced_fragment_coords]  # List to store all displaced structures\n",
    "\n",
    "    # Combine displaced coordinates with original ones\n",
    "    all_combined_coords = [np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)]  # List to store all combined structures\n",
    "\n",
    "    fragment_centroids = [fragment_centroids[0]]  # List to store all centroids\n",
    "\n",
    "    # Dissociation limit NEED AT LEAST 40 OF THEM MINIMUM\n",
    "    diss_lim = 50 # change with the output value in agnstrom from func(dissociation_limit)\n",
    "\n",
    "    for i in range(1, diss_lim):  # Iterate 50 times (adjust the number as needed) put this as to be the dissociation limit of each DFT run\n",
    "        \n",
    "        displacement_vector = [] \n",
    "\n",
    "        # Compute new set of coordinates for displaced fragments, change $displacement value in input file to tune the displacement\n",
    "        displaced_fragment_coords = displace_fragment(coords1, displacement_direction, displacement_step, i)\n",
    "        #print(f'Displaced fragment coord is: {displaced_fragment_coords}')\n",
    "\n",
    "        combined_coords = np.concatenate((coords_fixed, displaced_fragment_coords), axis=0)\n",
    "        all_combined_coords.append(combined_coords)\n",
    "\n",
    "        # Update centroids for the displaced structure\n",
    "        fragment_centroid = calculate_centroids([displaced_fragment_coords])\n",
    "        fragment_centroids.append(fragment_centroid[0])\n",
    "        print(f'Updated centroids:', fragment_centroid)\n",
    "\n",
    "        # Write displaced structure to file\n",
    "        output_file = Path(os.path.join(current_dir, f'displaced_structures/displaced_structure_{i}.xyz'))\n",
    "        write_displaced_xyz_file(output_file, coords_fixed, displaced_fragment_coords, atom_identities)\n",
    "\n",
    "        all_displaced_fragment_coords.append(displaced_fragment_coords)\n",
    "\n",
    "        # Compute distance between the fixed fragment centroid and all the atoms from the displaced fragment\n",
    "        centroid_to_displaced_distance = compute_distance_from_centroid(displaced_fragment_coords, centroids)\n",
    "        print(f'Distance between displaced coordinates and centroid is: {centroid_to_displaced_distance}')\n",
    "\n",
    "        # Write distances to file - needed for DFT calculations outputs\n",
    "        distance_output_file = Path(os.path.join(current_dir, f'distance_files/distances_structures_{i}.xyz'))\n",
    "        write_distances_file(distance_output_file, displaced_fragment_coords, centroid_to_displaced_distance, atom_identities, displacement_step)\n",
    "\n",
    "\n",
    "    # Plot initial topology for molecular fragments and centroids\n",
    "    fig = plot_starting_molecular_fragments(coords1, coords2, centroids)\n",
    "\n",
    "    # Generate colors for the plots based on displacement iteration\n",
    "    num_iterations = len(all_displaced_fragment_coords)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 1.0, num_iterations))\n",
    "\n",
    "    # Plot displaced molecular fragments and centroids\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot original fragments and centroids\n",
    "    ax.scatter(coords1[:, 0], coords1[:, 1], coords1[:, 2], color=colors[0], label='Molecule 1 (Original)')\n",
    "    ax.scatter(coords2[:, 0], coords2[:, 1], coords2[:, 2], color=colors[0], label='Molecule 2 (Original)')\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], color=colors[0], marker='x', s=100, label='Centroids (Original)')\n",
    "\n",
    "    # Plot displaced fragments and centroids\n",
    "    for i, displaced_coords in enumerate(all_displaced_fragment_coords[1:], start=1):\n",
    "        color = colors[i]\n",
    "        label = f'Iteration {i}'\n",
    "        ax.scatter(displaced_coords[:, 0], displaced_coords[:, 1], displaced_coords[:, 2], color=color, label=label)\n",
    "        ax.scatter(fragment_centroids[i][0], fragment_centroids[i][1], fragment_centroids[i][2], color=color, marker='x', s=100, label=f'Centroids ({label})')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # END TIMER: STOP TIMER AND PRINT\n",
    "    elapsed_time = timer() - start  # in seconds\n",
    "    print(f'Elapsed time for the code to run is: {elapsed_time}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: GenerateMLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "\n",
    "# current_dir = os.getcwd()\n",
    "# print(f'Current working directory is: {current_dir}')\n",
    "\n",
    "# root_directory = os.path.join(current_dir, 'Machine_learning/raw')\n",
    "# print(f'Dataset root directory is: {root_directory}')\n",
    "\n",
    "# output_csv_path = os.path.join(current_dir, 'Machine_learning/datasets/model_structures/test.csv')\n",
    "# print(f'Dataset directory is: {output_csv_path}')\n",
    "\n",
    "# generate_dataset = GenerateMLDataset(root_directory, output_csv_path)\n",
    "# generate_dataset.search_files()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules: AminoStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# toolbox = NONCOVToolbox()\n",
    "# amino_stats = toolbox.AminoStat()\n",
    "\n",
    "# # Example usage\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# protein_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spidersilks.txt')\n",
    "# spaced_sequence = os.path.join(current_dir, 'scratch/amino_acid_stats/spaced_spidersilks.txt')\n",
    "# count_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_count.txt')\n",
    "# plot_file = os.path.join(current_dir, 'scratch/amino_acid_stats/silks_amino_acid_statistics.pdf')\n",
    "\n",
    "# #amino_stats = AminoStat()\n",
    "\n",
    "# amino_stats.space_prot_seq(protein_sequence, spaced_sequence)\n",
    "# amino_stats.count_amino_acids(spaced_sequence, count_file)\n",
    "# amino_stats.plot_amino_acid_statistics(count_file, plot_file)\n",
    "\n",
    "# amino_stats.define_protein_domains()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
